[
  {
    "objectID": "discord.html",
    "href": "discord.html",
    "title": "Discord Channel",
    "section": "",
    "text": "First time only, use the invite link here\nAccess the Data Exploration Discord Channel here"
  },
  {
    "objectID": "discord.html#announcements",
    "href": "discord.html#announcements",
    "title": "Discord Channel",
    "section": "Announcements",
    "text": "Announcements\n\n\n\nMade with https://docs.widgetbot.io/"
  },
  {
    "objectID": "slides/09-data-wrangling.html#goals",
    "href": "slides/09-data-wrangling.html#goals",
    "title": "Week 9: Data Wrangling",
    "section": "Goals",
    "text": "Goals\n\ndefine the data wrangling cycle\nreview sanity checks on data\nreview common operations to manipulate data\nuse pandas to wrangle data in notebook"
  },
  {
    "objectID": "slides/09-data-wrangling.html#definition",
    "href": "slides/09-data-wrangling.html#definition",
    "title": "Week 9: Data Wrangling",
    "section": "Definition",
    "text": "Definition\nData wrangling is the process of cleaning, preprocessing and validating raw data before use"
  },
  {
    "objectID": "slides/09-data-wrangling.html#cycle",
    "href": "slides/09-data-wrangling.html#cycle",
    "title": "Week 9: Data Wrangling",
    "section": "Cycle",
    "text": "Cycle"
  },
  {
    "objectID": "slides/09-data-wrangling.html#section",
    "href": "slides/09-data-wrangling.html#section",
    "title": "Week 9: Data Wrangling",
    "section": "",
    "text": "shape –&gt; df.shape()\ncolumn names –&gt; df.column\ntypes of data –&gt; df.dtypes"
  },
  {
    "objectID": "slides/09-data-wrangling.html#section-1",
    "href": "slides/09-data-wrangling.html#section-1",
    "title": "Week 9: Data Wrangling",
    "section": "",
    "text": "If a column has a mix of strings and other data types (e.g., numbers or None values), pandas defaults to object. [GPT]"
  },
  {
    "objectID": "slides/09-data-wrangling.html#accessing-specific-rows-and-columns",
    "href": "slides/09-data-wrangling.html#accessing-specific-rows-and-columns",
    "title": "Week 9: Data Wrangling",
    "section": "Accessing specific rows and columns",
    "text": "Accessing specific rows and columns\nloc –&gt; df.loc[rows, cols] iloc –&gt; df.iloc[rows, cols by index]"
  },
  {
    "objectID": "slides/09-data-wrangling.html#creating-a-new-column-in-an-existing-df",
    "href": "slides/09-data-wrangling.html#creating-a-new-column-in-an-existing-df",
    "title": "Week 9: Data Wrangling",
    "section": "Creating a new column in an existing df",
    "text": "Creating a new column in an existing df\ndf[‘new’] = # expression\n\nnote that a new column can only be added if it is the same length as the other existing columns"
  },
  {
    "objectID": "slides/09-data-wrangling.html#concatenation",
    "href": "slides/09-data-wrangling.html#concatenation",
    "title": "Week 9: Data Wrangling",
    "section": "Concatenation",
    "text": "Concatenation\nAlong Rows –&gt; axis=0 Along Cols –&gt; axis=1\npd.concat(df1, df2, axis=1)"
  },
  {
    "objectID": "slides/09-data-wrangling.html#reformatting-strings",
    "href": "slides/09-data-wrangling.html#reformatting-strings",
    "title": "Week 9: Data Wrangling",
    "section": "Reformatting Strings",
    "text": "Reformatting Strings\nRegular Expressions inside of pd.DataFrame.str.replace()\n\n[] Groups together characters to search for\n[^...] Negation (matches anything not inside the brackets).\na-z Matches lowercase letters a to z.\n+ Matches one or more occurrences of the unwanted characters."
  },
  {
    "objectID": "slides/09-data-wrangling.html#reformatting-strings-1",
    "href": "slides/09-data-wrangling.html#reformatting-strings-1",
    "title": "Week 9: Data Wrangling",
    "section": "Reformatting Strings",
    "text": "Reformatting Strings\ndf[‘YOUR COLUMN’].str.split(‘YOUR DELIMITER’, expand=True)"
  },
  {
    "objectID": "slides/09-data-wrangling.html#data-wrangling-activity",
    "href": "slides/09-data-wrangling.html#data-wrangling-activity",
    "title": "Week 9: Data Wrangling",
    "section": "Data Wrangling Activity",
    "text": "Data Wrangling Activity\ndata_wrangling_activity.ipynb"
  },
  {
    "objectID": "slides/13-linear-regression.html#goals",
    "href": "slides/13-linear-regression.html#goals",
    "title": "Week 13: Linear Regression",
    "section": "Goals",
    "text": "Goals\n\nLines\nConnection to Correlation\nExamples\nEvaluating Lines"
  },
  {
    "objectID": "slides/13-linear-regression.html#formula-for-a-line",
    "href": "slides/13-linear-regression.html#formula-for-a-line",
    "title": "Week 13: Linear Regression",
    "section": "Formula for a Line",
    "text": "Formula for a Line\n\\[\ny = mx + b\n\\]\n\nx and y are variables in a sample\nm is the slope relating the two\nb is the y-intercept"
  },
  {
    "objectID": "slides/13-linear-regression.html#another-formula-for-a-line",
    "href": "slides/13-linear-regression.html#another-formula-for-a-line",
    "title": "Week 13: Linear Regression",
    "section": "Another Formula for a Line",
    "text": "Another Formula for a Line\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\n\nx and y are variables in a sample with N observations\nx is the independent variable\ny is the dependent variable, it depends on x\n\\(\\beta_1\\) is the slope\n\\(\\beta_0\\) is the y-intercept"
  },
  {
    "objectID": "slides/13-linear-regression.html#slope-indicates-steepness",
    "href": "slides/13-linear-regression.html#slope-indicates-steepness",
    "title": "Week 13: Linear Regression",
    "section": "Slope Indicates Steepness",
    "text": "Slope Indicates Steepness"
  },
  {
    "objectID": "slides/13-linear-regression.html#slope-is-describes-the-relationship-between-x-and-y",
    "href": "slides/13-linear-regression.html#slope-is-describes-the-relationship-between-x-and-y",
    "title": "Week 13: Linear Regression",
    "section": "Slope is Describes The Relationship Between x and y",
    "text": "Slope is Describes The Relationship Between x and y\n\n\n\nif x and y were identical, the relationship would be 1:1\nif y never changes for any x, the relationship is 0\nsounds like a correlation!"
  },
  {
    "objectID": "slides/13-linear-regression.html#correlation",
    "href": "slides/13-linear-regression.html#correlation",
    "title": "Week 13: Linear Regression",
    "section": "Correlation",
    "text": "Correlation\nPearson Correction, \\(r\\) is defined:\n\\[\nr = {\\Sigma_{i = 1}^N (x_i - \\bar x)(y_i - \\bar y) \\over \\sqrt {\\Sigma_{i = 1}^N (x_i - \\bar x)^2 \\times \\Sigma_{i = 1}^N(y_i - \\bar y)^2}}\n\\]"
  },
  {
    "objectID": "slides/13-linear-regression.html#slope",
    "href": "slides/13-linear-regression.html#slope",
    "title": "Week 13: Linear Regression",
    "section": "Slope",
    "text": "Slope\nSlope, \\(\\beta_1\\) is defined:\n\\[\n\\beta_1 = {\\Sigma_{i = 1}^N (x_i - \\bar x)(y_i - \\bar y) \\over \\Sigma_{i = 1}^N (x_i - \\bar x)^2}\n\\]"
  },
  {
    "objectID": "slides/13-linear-regression.html#together",
    "href": "slides/13-linear-regression.html#together",
    "title": "Week 13: Linear Regression",
    "section": "Together",
    "text": "Together\n\\[\nr = {\\Sigma_{i = 1}^N (x_i - \\bar x)(y_i - \\bar y) \\over \\sqrt {\\Sigma_{i = 1}^N (x_i - \\bar x)^2 \\times \\Sigma_{i = 1}^N(y_i - \\bar y)^2}}\n\\]\n-———\n\\[\n\\beta_1 = {\\Sigma_{i = 1}^N (x_i - \\bar x)(y_i - \\bar y) \\over \\Sigma_{i = 1}^N (x_i - \\bar x)^2}\n\\]"
  },
  {
    "objectID": "slides/13-linear-regression.html#calculating-the-intercept",
    "href": "slides/13-linear-regression.html#calculating-the-intercept",
    "title": "Week 13: Linear Regression",
    "section": "Calculating the intercept",
    "text": "Calculating the intercept\nIf the slope of a line is found, then the intercept can be found\n\n\n\\[\n\\beta_1 = {\\Sigma_{i = 1}^N (x_i - \\bar x)(y_i - \\bar y) \\over \\Sigma_{i = 1}^N (x_i - \\bar x)^2}\n\\]\n\\[\n\\bar y = \\beta_0 + \\beta_1 \\bar x\n\\]\n\\[\n\\beta_0 = \\bar y - \\beta_1 \\bar x\n\\]"
  },
  {
    "objectID": "slides/13-linear-regression.html#song-popularity-dataset",
    "href": "slides/13-linear-regression.html#song-popularity-dataset",
    "title": "Week 13: Linear Regression",
    "section": "Song Popularity Dataset",
    "text": "Song Popularity Dataset\n\nimport pandas as pd\n\ndf = pd.read_csv('https://raw.githubusercontent.com/allegheny-college-cmpsc-105-spring-2025/data-relationships-starter/refs/heads/main/data/data-analysis-kaggle-song-popularity-data.csv')\ndf\n\n\n\n\n\n\n\n\nsong_name\nsong_popularity\nsong_duration_ms\nacousticness\ndanceability\nenergy\ninstrumentalness\nkey\nliveness\nloudness\naudio_mode\nspeechiness\ntempo\ntime_signature\naudio_valence\n\n\n\n\n0\nBoulevard of Broken Dreams\n73\n262333\n0.005520\n0.496\n0.682\n0.000029\n8\n0.0589\n-4.095\n1\n0.0294\n167.060\n4\n0.474\n\n\n1\nIn The End\n66\n216933\n0.010300\n0.542\n0.853\n0.000000\n3\n0.1080\n-6.407\n0\n0.0498\n105.256\n4\n0.370\n\n\n2\nSeven Nation Army\n76\n231733\n0.008170\n0.737\n0.463\n0.447000\n0\n0.2550\n-7.828\n1\n0.0792\n123.881\n4\n0.324\n\n\n3\nBy The Way\n74\n216933\n0.026400\n0.451\n0.970\n0.003550\n0\n0.1020\n-4.938\n1\n0.1070\n122.444\n4\n0.198\n\n\n4\nHow You Remind Me\n56\n223826\n0.000954\n0.447\n0.766\n0.000000\n10\n0.1130\n-5.065\n1\n0.0313\n172.011\n4\n0.574\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n18830\nLet It Breathe\n60\n159645\n0.893000\n0.500\n0.151\n0.000065\n11\n0.1110\n-16.107\n1\n0.0348\n113.969\n4\n0.300\n\n\n18831\nAnswers\n60\n205666\n0.765000\n0.495\n0.161\n0.000001\n11\n0.1050\n-14.078\n0\n0.0301\n94.286\n4\n0.265\n\n\n18832\nSudden Love (Acoustic)\n23\n182211\n0.847000\n0.719\n0.325\n0.000000\n0\n0.1250\n-12.222\n1\n0.0355\n130.534\n4\n0.286\n\n\n18833\nGentle on My Mind\n55\n352280\n0.945000\n0.488\n0.326\n0.015700\n3\n0.1190\n-12.020\n1\n0.0328\n106.063\n4\n0.323\n\n\n18834\nUp to Me\n60\n193533\n0.911000\n0.640\n0.381\n0.000254\n4\n0.1040\n-11.790\n1\n0.0302\n91.490\n4\n0.581\n\n\n\n\n18835 rows × 15 columns"
  },
  {
    "objectID": "slides/13-linear-regression.html#visualize",
    "href": "slides/13-linear-regression.html#visualize",
    "title": "Week 13: Linear Regression",
    "section": "Visualize",
    "text": "Visualize\n\nimport matplotlib.pyplot as plt\n\npop = df.song_popularity\ndur = df.song_duration_ms/(60 * 1000) # duration in minutes\n\nplt.figure()\nplt.scatter(pop, dur)\nplt.xlabel('Popularity')\nplt.ylabel('Duration (minutes)')\n\nText(0, 0.5, 'Duration (minutes)')"
  },
  {
    "objectID": "slides/13-linear-regression.html#correlation-1",
    "href": "slides/13-linear-regression.html#correlation-1",
    "title": "Week 13: Linear Regression",
    "section": "Correlation",
    "text": "Correlation\nFor all songs, what is the correlation between song popularity and song duration?\n\npop = df.song_popularity\ndur = df.song_duration_ms/(60 * 1000) # duration in minutes\n\nnumerator = sum((pop - pop.mean()) * (dur - dur.mean()))\ndenominator = (sum( (pop - pop.mean())**2 ) * sum( (dur - dur.mean())**2 )) ** 0.5\n\nr = numerator / denominator\nprint(r)\n\n-0.01889940687102933"
  },
  {
    "objectID": "slides/13-linear-regression.html#slope-1",
    "href": "slides/13-linear-regression.html#slope-1",
    "title": "Week 13: Linear Regression",
    "section": "Slope",
    "text": "Slope\nWhat is the slope that fits an optimal line?\n\npop = df.song_popularity\ndur = df.song_duration_ms/(60 * 1000) # duration in minutes\n\nnumerator = sum((pop - pop.mean()) * (dur - dur.mean()))\ndenominator = (sum( (pop - pop.mean())**2 ))\n\nslope = numerator / denominator\nprint(slope)\n\n-0.0008611467607479652"
  },
  {
    "objectID": "slides/13-linear-regression.html#intercept",
    "href": "slides/13-linear-regression.html#intercept",
    "title": "Week 13: Linear Regression",
    "section": "Intercept",
    "text": "Intercept\n\n# y = m * x + b\n# dur  = slope * pop + intercept\n# intercept = dur - slope * pop\n\nintercept = dur.mean() - (slope * pop.mean())\nprint(intercept)\n\n3.682493576012533"
  },
  {
    "objectID": "slides/13-linear-regression.html#add-line-to-figure",
    "href": "slides/13-linear-regression.html#add-line-to-figure",
    "title": "Week 13: Linear Regression",
    "section": "Add Line to Figure",
    "text": "Add Line to Figure\n\nplt.figure()\nplt.scatter(pop, dur)\nplt.xlabel('Popularity')\nplt.ylabel('Duration (minutes)')\n\nplt.plot([0, 100], [slope * 0 + intercept, slope * 100 + intercept], 'r')\nplt.show()"
  },
  {
    "objectID": "slides/13-linear-regression.html#add-line-to-figure-1",
    "href": "slides/13-linear-regression.html#add-line-to-figure-1",
    "title": "Week 13: Linear Regression",
    "section": "Add Line to Figure",
    "text": "Add Line to Figure\nplt.plot([0, 100], [slope * 0 + intercept, slope * 100 + intercept], 'r')\n\n\nnote how in the previous slide, I had to pick two x positions [low popularity, high popularity], then calculate the y using the formula of the line!\nfor x = 0, y = slope * 0 + intercept\nfor x = 100, y = slope * 100 + intercept"
  },
  {
    "objectID": "slides/13-linear-regression.html#evaluating-lines-1",
    "href": "slides/13-linear-regression.html#evaluating-lines-1",
    "title": "Week 13: Linear Regression",
    "section": "Evaluating Lines",
    "text": "Evaluating Lines\n\n\nif you have an x-value and a formula for a line, the y-value can be calculated!\nin the current example, I have a lot of x-values, pop\nusing pop, I can compute PREDICTED y-values, \\(\\hat dur\\)\nthen I can compare \\(dur\\) with \\(\\hat dur\\)"
  },
  {
    "objectID": "slides/13-linear-regression.html#comparing-predicted-and-actual-y-values",
    "href": "slides/13-linear-regression.html#comparing-predicted-and-actual-y-values",
    "title": "Week 13: Linear Regression",
    "section": "Comparing Predicted and Actual y-values",
    "text": "Comparing Predicted and Actual y-values\n\npred_dur = slope * pop + intercept\nerror = pred_dur - dur # compare using subtraction\nMSE = (error ** 2).mean() # mean squared error\nSSE = sum(error ** 2) # sum of squared error\nprint(MSE)\nprint(SSE)\n\n0.9958461405203248\n18756.762056700198\n\n\n\n\nsquaring errors makes everything positive, and the exaggerates large errors\nMSE is commonly used to compare models\nif this topic interests you, study machine learning to learn more about training & overfitting"
  },
  {
    "objectID": "slides/13-linear-regression.html#more-evaluation",
    "href": "slides/13-linear-regression.html#more-evaluation",
    "title": "Week 13: Linear Regression",
    "section": "More Evaluation",
    "text": "More Evaluation\n\n\nstandard deviation for y-values would be \\(\\sqrt{ \\Sigma_i^N(y_i - \\bar y)^2  \\over N}\\)\nIn linear regression the numerator is the Total Sum of Squares, \\(SST = \\Sigma_i^N(y_i - \\bar y)^2\\)\nWe saw above, the Sum of Squared Error is \\(SSE = \\Sigma_i^N(\\hat y_i - y_i)^2\\)\nSST is made of SSE + SSR (Sum of Regression Errors), so SSR = SST - SSE\nOr, \\(SSR = \\Sigma_i^N(\\hat y_i - \\bar y)^2\\)\nFinally, the percentage of variability in y that is explained by the model is \\(R^2 = {SSR \\over SST}\\)\nAND it is literally the pearson correlation squared"
  },
  {
    "objectID": "slides/13-linear-regression.html#more-evaluation-in-code",
    "href": "slides/13-linear-regression.html#more-evaluation-in-code",
    "title": "Week 13: Linear Regression",
    "section": "More Evaluation in Code",
    "text": "More Evaluation in Code\n\npred_dur = slope * pop + intercept\nerror = pred_dur - dur # compare using subtraction\n\nSSE = sum(error ** 2) # sum of squared error\nSST = sum((dur - dur.mean())**2) # total sum of squares\nSSR = SST - SSE\n\nprint(\"this is a sanity check for SSR: \", sum((pred_dur - dur.mean())**2), SSR) \n\nR_squared = SSR/SST\nprint(\"Raw R_squared: \", R_squared)\nprint(\"Percentage of variance explained by model: \", 100 * R_squared)\n\nprint(\"Pearson correlation coefficient from earlier code cell: \", r)\nprint(\"Pearson correlation squared: \", r ** 2)\n\nthis is a sanity check for SSR:  6.7020763475397525 6.70207634774124\nRaw R_squared:  0.0003571875800874598\nPercentage of variance explained by model:  0.03571875800874598\nPearson correlation coefficient from earlier code cell:  -0.01889940687102933\nPearson correlation squared:  0.0003571875800767106"
  },
  {
    "objectID": "slides/13-linear-regression.html#using-scipy-to-get-probability",
    "href": "slides/13-linear-regression.html#using-scipy-to-get-probability",
    "title": "Week 13: Linear Regression",
    "section": "Using Scipy to get Probability",
    "text": "Using Scipy to get Probability\nimport scipy\n\nslope, intercept, r, p, se = scipy.stats.linregress(pop, dur)\nCompare with\nimport scipy\n\nr, p = scipy.stats.pearsonr(pop, dur)"
  },
  {
    "objectID": "slides/13-linear-regression.html#end",
    "href": "slides/13-linear-regression.html#end",
    "title": "Week 13: Linear Regression",
    "section": "End",
    "text": "End"
  },
  {
    "objectID": "slides/14-storytelling.html#goals",
    "href": "slides/14-storytelling.html#goals",
    "title": "Week 14: Storytelling",
    "section": "Goals",
    "text": "Goals\n\nTelling Your Story\nSupporting Your Story\n\nFinding Scholarly Research\nTracing References\nUsing References vs Explaining References"
  },
  {
    "objectID": "slides/14-storytelling.html#main-steps",
    "href": "slides/14-storytelling.html#main-steps",
    "title": "Week 14: Storytelling",
    "section": "Main Steps",
    "text": "Main Steps\n\n\n\nAbstract\n\nMotivation\nProblem or Gap in Knowledge\nHypothesis or Question\nData\nActionable Steps\nEvaluations\nInterpretation"
  },
  {
    "objectID": "slides/14-storytelling.html#main-steps-continued",
    "href": "slides/14-storytelling.html#main-steps-continued",
    "title": "Week 14: Storytelling",
    "section": "Main Steps Continued",
    "text": "Main Steps Continued\n\n\n\nBackground\n\nMotivation (more detail with ref)\nProblem or Gap in Knowledge (more detail with ref)\nHypothesis or Question (more detail)\n\nMethods\n\nData\nActionable Steps\nHow evaluations will be done\n\nResults\n\nEvaluations (with visualizations)\n\nDiscussion\n\nInterpretation of results (more detail)"
  },
  {
    "objectID": "slides/14-storytelling.html#todays-focus-abstract",
    "href": "slides/14-storytelling.html#todays-focus-abstract",
    "title": "Week 14: Storytelling",
    "section": "Today’s Focus: Abstract",
    "text": "Today’s Focus: Abstract\n\n\nMotivation\nProblem or Gap in Knowledge\nHypothesis or Question\nData\nActionable Steps\nEvaluations\nInterpretation"
  },
  {
    "objectID": "slides/14-storytelling.html#motivation-example",
    "href": "slides/14-storytelling.html#motivation-example",
    "title": "Week 14: Storytelling",
    "section": "Motivation Example",
    "text": "Motivation Example\n\n\nIdentify your research motivation\nDo not use personal goals\n\nX Personal goal: “I wanted to learn how to do clustering because I think employers desire that skill”\n\nDo use personal or academic knowledge\n\nPersonal knowledge: “Individual golfers often have clubs made of different materials.”"
  },
  {
    "objectID": "slides/14-storytelling.html#problem-or-gap-in-knowledge-example",
    "href": "slides/14-storytelling.html#problem-or-gap-in-knowledge-example",
    "title": "Week 14: Storytelling",
    "section": "Problem or Gap in Knowledge Example",
    "text": "Problem or Gap in Knowledge Example\n\n“It is unclear why having different materials matters.”"
  },
  {
    "objectID": "slides/14-storytelling.html#hypothesis-or-question-example",
    "href": "slides/14-storytelling.html#hypothesis-or-question-example",
    "title": "Week 14: Storytelling",
    "section": "Hypothesis or Question Example",
    "text": "Hypothesis or Question Example\n\n“I want to know if the materials actually make a difference in how well the players play.”"
  },
  {
    "objectID": "slides/14-storytelling.html#data-example",
    "href": "slides/14-storytelling.html#data-example",
    "title": "Week 14: Storytelling",
    "section": "Data Example",
    "text": "Data Example\n\n“I will use information from public sources about which players use which materials and how highly ranked each player is.”"
  },
  {
    "objectID": "slides/14-storytelling.html#actionable-steps-example",
    "href": "slides/14-storytelling.html#actionable-steps-example",
    "title": "Week 14: Storytelling",
    "section": "Actionable Steps Example",
    "text": "Actionable Steps Example\n\n“I will examine if players who use the same materials have similar rankings”"
  },
  {
    "objectID": "slides/14-storytelling.html#evaluations-example",
    "href": "slides/14-storytelling.html#evaluations-example",
    "title": "Week 14: Storytelling",
    "section": "Evaluations Example",
    "text": "Evaluations Example\n\n“For each material, I will evaluate the”similarity” of rankings by computing the mean and standard deviation and comparing those to the mean and standard deviation for every other material”"
  },
  {
    "objectID": "slides/14-storytelling.html#interpretation-examples",
    "href": "slides/14-storytelling.html#interpretation-examples",
    "title": "Week 14: Storytelling",
    "section": "Interpretation Examples",
    "text": "Interpretation Examples\n\n\nConnect back to the hypothesis.\n\n“If the rankings are found to not be the same from material to material, that indicates that materials may be related to player rankings. Players could therefore consider trying materials that highly ranked players use.”\n“If the rankings are found to be the same from material to material, that indicates that materials may not be related to player rankings. Players could therefore try various materials.”"
  },
  {
    "objectID": "slides/14-storytelling.html#full-chain-of-logic",
    "href": "slides/14-storytelling.html#full-chain-of-logic",
    "title": "Week 14: Storytelling",
    "section": "Full chain of logic",
    "text": "Full chain of logic\n\nMotivation, Problem or Gap in Knowledge, Hypothesis or Question, Data, Actionable Steps, Evaluations, Interpretation\n\n\nIndividual golfers often have clubs made of different materials. It is unclear why having different materials matters. This research is about understanding if the materials actually make a difference in how well the players play. Information from public sources about which players use which materials and how highly ranked each player is will be explored to answer the question. Specifically, players who use the same materials will be grouped together, and their rankings will evaluated. For each material, the mean and standard deviation of the players rankings will be compared. If the rankings are found to not be the same from material to material, that indicates that materials may be related to player rankings. Players could therefore consider using the same materials that highly ranked players use."
  },
  {
    "objectID": "slides/14-storytelling.html#finding-scholarly-research-1",
    "href": "slides/14-storytelling.html#finding-scholarly-research-1",
    "title": "Week 14: Storytelling",
    "section": "Finding Scholarly Research",
    "text": "Finding Scholarly Research\n\n\nWhere are you searching?\nWhat are searching for?\nChoosing useful papers out of the masses"
  },
  {
    "objectID": "slides/14-storytelling.html#where",
    "href": "slides/14-storytelling.html#where",
    "title": "Week 14: Storytelling",
    "section": "Where?",
    "text": "Where?\nDatabases!\n\n\nhttps://allegheny.libguides.com/az.php\nACM (Association for Computing Machinery)\nScienceDirect\nTaylor & Francis\nScopus"
  },
  {
    "objectID": "slides/14-storytelling.html#what",
    "href": "slides/14-storytelling.html#what",
    "title": "Week 14: Storytelling",
    "section": "What?",
    "text": "What?\nKeywords!\n\n\nuse keyword searches\ncombine analysis method, field, topic, outcome measure\nexample: classification, sports, golf, materials, player ranking"
  },
  {
    "objectID": "slides/14-storytelling.html#what-classification-sports-golf-materials-player-ranking",
    "href": "slides/14-storytelling.html#what-classification-sports-golf-materials-player-ranking",
    "title": "Week 14: Storytelling",
    "section": "What? (classification, sports, golf, materials, player ranking)",
    "text": "What? (classification, sports, golf, materials, player ranking)\nCheck all assumptions in your literature review\n\n\nLR 1: GENERAL: does gear impact athletes?\n\nsearch: sports relationship of player ranking with jersey material\nsearch: sports relationship of player success with court preparations\nsearch: sports relationship of player success with shoe weight\n\nnote: these searches probably will be about different sports, but that is good! It shows the relevance of your question broadly."
  },
  {
    "objectID": "slides/14-storytelling.html#what-classification-sports-golf-materials-player-ranking-1",
    "href": "slides/14-storytelling.html#what-classification-sports-golf-materials-player-ranking-1",
    "title": "Week 14: Storytelling",
    "section": "What? (classification, sports, golf, materials, player ranking)",
    "text": "What? (classification, sports, golf, materials, player ranking)\n\n\nLR 2: NARROW SLIGHTLY: does golf club material impact golfers?\n\nsearch: golf relationship of club material with hit accuracy\nsearch: golf relationship of club material with hit strength\n\nLR 3: MOST NARROW: are the best golfers all using the same materials or is it something else?\n\nsearch: classifying golfers by club materials\nsearch: classifying golfers by physical attributes"
  },
  {
    "objectID": "slides/14-storytelling.html#what-classification-sports-golf-materials-player-ranking-2",
    "href": "slides/14-storytelling.html#what-classification-sports-golf-materials-player-ranking-2",
    "title": "Week 14: Storytelling",
    "section": "What? (classification, sports, golf, materials, player ranking)",
    "text": "What? (classification, sports, golf, materials, player ranking)\nCheck definitions even if you have an idea of what they mean.\n\n\nLR 4: DEFINE STANDARDS\n\nsearch: golf player analysis (how are golfers usually evaluated?)\nsearch: golf club materials analysis (what else has been examined and how?)\nsearch: textbook chapter on classification (is the method applicable and how does it work?)\nsearch: determinants of player ranking sports (where does ranking even come from?)"
  },
  {
    "objectID": "slides/14-storytelling.html#choosing-papers",
    "href": "slides/14-storytelling.html#choosing-papers",
    "title": "Week 14: Storytelling",
    "section": "Choosing Papers",
    "text": "Choosing Papers\n\n\nEach search will probably bring up dozens of results\nLook for papers that have familiar authors\nLook for papers that are from reputable institutions\nLook for papers that have many citations\nFor each search, try to find a foundational paper, and one on new developments"
  },
  {
    "objectID": "slides/14-storytelling.html#find-the-foundation",
    "href": "slides/14-storytelling.html#find-the-foundation",
    "title": "Week 14: Storytelling",
    "section": "Find the foundation",
    "text": "Find the foundation\n\nlook at references list\nfind oldest date with on-topic content\nrepeat this from a few starting points"
  },
  {
    "objectID": "slides/14-storytelling.html#find-popular-theories-stable",
    "href": "slides/14-storytelling.html#find-popular-theories-stable",
    "title": "Week 14: Storytelling",
    "section": "Find popular theories, stable",
    "text": "Find popular theories, stable\n\nlook at references list\nwhat names appear in multiple articles?\nread intros\nwhat key ideas come up in multiple papers?"
  },
  {
    "objectID": "slides/14-storytelling.html#find-the-latest-in-development",
    "href": "slides/14-storytelling.html#find-the-latest-in-development",
    "title": "Week 14: Storytelling",
    "section": "Find the latest, in development",
    "text": "Find the latest, in development\n\nlook at cited by list\nthese are references that are more recent\nfollow the links to newer papers"
  },
  {
    "objectID": "slides/14-storytelling.html#why-are-you-reading",
    "href": "slides/14-storytelling.html#why-are-you-reading",
    "title": "Week 14: Storytelling",
    "section": "Why are you reading?",
    "text": "Why are you reading?\n\nYou may read and reread the same set of papers for different reasons\nwhat analysis method did they use?\nWhat data did they use?\nWhat assumptions did they make?\nWhat was their take home message?"
  },
  {
    "objectID": "slides/14-storytelling.html#using-references",
    "href": "slides/14-storytelling.html#using-references",
    "title": "Week 14: Storytelling",
    "section": "Using References",
    "text": "Using References\nIn a research narrative, use references to back up your points. Answer, “how do you know” for everything!\n\nIndividual golfers often have clubs made of different materials [References about variety of clubs player have]. It is unclear why having different materials matters [Ref questioning difference and similarities, perhaps competing views]. This research is about understanding if the materials actually make a difference in how well the players play. Information from public sources about which players use which materials and how highly ranked each player is will be explored to answer the question. Specifically, players who use the same materials will be grouped together, and their rankings will evaluated. For each material, the mean and standard deviation of the players rankings will be compared. If the rankings are found to not be the same from material to material, that indicates that materials may be related to player rankings. Players could therefore consider using the same materials that highly ranked players use.\n\nNotice that the references did not have to be explained."
  },
  {
    "objectID": "slides/14-storytelling.html#end",
    "href": "slides/14-storytelling.html#end",
    "title": "Week 14: Storytelling",
    "section": "End",
    "text": "End"
  },
  {
    "objectID": "slides/10-data-descriptors.html#goals",
    "href": "slides/10-data-descriptors.html#goals",
    "title": "Week 10: Data Descriptors",
    "section": "Goals",
    "text": "Goals\n\nCentral Tendencies\n\nMode, Median, Mean\n\nDistributions\n\nHistograms, Range, Standard Deviation, Z-scores\n\nStats in Practice\n\nPandas\nClass Activity"
  },
  {
    "objectID": "slides/10-data-descriptors.html#mode-definition",
    "href": "slides/10-data-descriptors.html#mode-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Mode Definition",
    "text": "Mode Definition\nThe most common value in a sample. Usually a measure of “central tendency”."
  },
  {
    "objectID": "slides/10-data-descriptors.html#mode-examples",
    "href": "slides/10-data-descriptors.html#mode-examples",
    "title": "Week 10: Data Descriptors",
    "section": "Mode Examples",
    "text": "Mode Examples\n3, 4, 5, 6, 7, 7, 7, 8, 8, 9\n\n7\n\n\n8, 5, 3, 7, 4, 6, 7, 8, 9, 7\n\n\n7\n\n\n3, 4, 5, 6, 7, 7, 7, 8, 8, 8, 9\n\n\n\nUse the average in case of multiple modes, or a set with both modes\n7.5 or {7,8}"
  },
  {
    "objectID": "slides/10-data-descriptors.html#median-definition",
    "href": "slides/10-data-descriptors.html#median-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Median Definition",
    "text": "Median Definition\nMiddle value once a variable has been sorted low to high"
  },
  {
    "objectID": "slides/10-data-descriptors.html#median-example",
    "href": "slides/10-data-descriptors.html#median-example",
    "title": "Week 10: Data Descriptors",
    "section": "Median Example",
    "text": "Median Example\n\n\nraw: 3, 4, 7, 2, 3, 7, 4, 2, 4, 7, 4\nsorted: 2, 2, 3, 3, 4, 4, 4, 4, 7, 7, 7\n6th is middle of 11: 4\nTake mean if there are two middles"
  },
  {
    "objectID": "slides/10-data-descriptors.html#mean-definition",
    "href": "slides/10-data-descriptors.html#mean-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Mean Definition",
    "text": "Mean Definition\nSum of all the values in a sample divided by the number of values.\n\\[\n\\bar x = {\\Sigma_{i = 1}^{N} x_i \\over N}\n\\]"
  },
  {
    "objectID": "slides/10-data-descriptors.html#range-definition",
    "href": "slides/10-data-descriptors.html#range-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Range Definition",
    "text": "Range Definition\nDistance between lowest and highest values in a variable (subtract high minus low)\n\n\nraw: 3, 4, 7, 2, 3, 7, 4, 2, 4, 7, 4\nsorted: 2, 2, 3, 3, 4, 4, 4, 4, 7, 7, 7\nhighest: 7\nlowest: 2\nrange: 7 - 2 –&gt; 5"
  },
  {
    "objectID": "slides/10-data-descriptors.html#quartiles-definition",
    "href": "slides/10-data-descriptors.html#quartiles-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Quartiles Definition",
    "text": "Quartiles Definition\nThe middle value (median), the middle value of the lower half (lower quartile), the middle value of the upper half (upper quartile)\n\n\nraw: 3, 4, 7, 2, 3, 7, 4, 2, 4, 7, 4\nsorted: 2, 2, 3, 3, 4, 4, 4, 4, 7, 7, 7\nmiddle is element 6 out of 11: 4\nlower quartile is element 3 out of 5: 3\nupper quartile is element 3 out of 5: 7\nexclude the median in calculating the uq and lq"
  },
  {
    "objectID": "slides/10-data-descriptors.html#box-plots",
    "href": "slides/10-data-descriptors.html#box-plots",
    "title": "Week 10: Data Descriptors",
    "section": "Box Plots",
    "text": "Box Plots\nVisualizations of quartiles and range (and mean and outliers)"
  },
  {
    "objectID": "slides/10-data-descriptors.html#box-plots-1",
    "href": "slides/10-data-descriptors.html#box-plots-1",
    "title": "Week 10: Data Descriptors",
    "section": "Box Plots",
    "text": "Box Plots\nSketch a box plot for the following data:\n\nraw: 3, 4, 7, 2, 3, 7, 4, 2, 4, 7, 4\nsorted: 2, 2, 3, 3, 4, 4, 4, 4, 7, 7, 7\nmiddle is element 6 out of 11: 4\nlq is element 3 out of 5: 3\nuq is element -3 out of 5: 7"
  },
  {
    "objectID": "slides/10-data-descriptors.html#variance-definition",
    "href": "slides/10-data-descriptors.html#variance-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Variance Definition",
    "text": "Variance Definition\nDescribes the spread of the data and how tightly clustered around the mean it is.\n\n\nMathematically, it is the normalized sum of squared errors.\nErrors are comparisons of each data point with the mean (subtraction)\nSquaring makes all errors positive and penalizes large errors\nSumming and normalizing is like finding the average squared error\n\\(\\sigma^2\\) represents variance\n\n\n\n\\[\n\\sigma^2 = {\\Sigma_{i = 1}^{N}(x_i - \\bar x)^2 \\over N-1}\n\\]"
  },
  {
    "objectID": "slides/10-data-descriptors.html#standard-deviation-definition",
    "href": "slides/10-data-descriptors.html#standard-deviation-definition",
    "title": "Week 10: Data Descriptors",
    "section": "Standard Deviation Definition",
    "text": "Standard Deviation Definition\nSquare root of variance. Describes the spread of the data and how tightly clustered around the mean it is.\n\n\\[\n\\sigma^2 = {\\Sigma_{i = 1}^{N}(x_i - \\bar x)^2 \\over N-1}\n\\] \\[\n\\sigma = \\sqrt{\\Sigma_{i = 1}^{N}(x_i - \\bar x)^2 \\over N-1}\n\\]"
  },
  {
    "objectID": "slides/10-data-descriptors.html#visualizations-of-standard-deviation",
    "href": "slides/10-data-descriptors.html#visualizations-of-standard-deviation",
    "title": "Week 10: Data Descriptors",
    "section": "Visualizations of Standard Deviation",
    "text": "Visualizations of Standard Deviation\n\nsmall STD –&gt; narrow distribution of data, most is close to the mean\nlarge STD –&gt; wide distribution of data, a lot is not close to the mean\nx axis is the variable (e.g. birth weight), y axis is count or frequency or proportion (how many babies born with that weight)"
  },
  {
    "objectID": "slides/10-data-descriptors.html#visualization-of-distributions",
    "href": "slides/10-data-descriptors.html#visualization-of-distributions",
    "title": "Week 10: Data Descriptors",
    "section": "Visualization of Distributions",
    "text": "Visualization of Distributions\nHistograms show spread as well as distribution shape.\n\nWhich distribution might describe adult human height?\nWhich distribution might describe age frequencies in the human population?\nWhich distribution might describe median household income in USA?"
  },
  {
    "objectID": "slides/10-data-descriptors.html#normal-distribution-terminology-overload",
    "href": "slides/10-data-descriptors.html#normal-distribution-terminology-overload",
    "title": "Week 10: Data Descriptors",
    "section": "Normal Distribution Terminology Overload",
    "text": "Normal Distribution Terminology Overload\n\nNormal\nBell-Shaped\nGaussian\nStandard Normal (mean 0, std 1)"
  },
  {
    "objectID": "slides/10-data-descriptors.html#z-scores",
    "href": "slides/10-data-descriptors.html#z-scores",
    "title": "Week 10: Data Descriptors",
    "section": "Z-scores",
    "text": "Z-scores\nA linear transformation that converts data points into measures of how many standard deviations away the data is from the mean.\n\ndata point is compared with mean\nthe difference is normalized with respect to the standard deviation (division)\nz-score of 0 means that the data point is identical to the mean\nnegative z-score means that the data point is smaller than the mean\npositive z-score means that the data point is larger than the mean\n\n\\[\nz_i = {x_i - \\bar x \\over \\sigma}\n\\]"
  },
  {
    "objectID": "slides/10-data-descriptors.html#z-scored-normal-data",
    "href": "slides/10-data-descriptors.html#z-scored-normal-data",
    "title": "Week 10: Data Descriptors",
    "section": "Z-scored Normal Data",
    "text": "Z-scored Normal Data\nWhen normal (gaussian) data is z-scored, the distribution looks like this:\n\n\n\n\nx axis is the z-score of normal data\ny axis is the proportion of data with that z-score\narea totals 1, or 100%\nthe standard deviation of z-scored data is always 1\nthe mean of z-scored data is always 0"
  },
  {
    "objectID": "slides/10-data-descriptors.html#pandas-examples",
    "href": "slides/10-data-descriptors.html#pandas-examples",
    "title": "Week 10: Data Descriptors",
    "section": "Pandas Examples",
    "text": "Pandas Examples\n\n\nmean - df.mean() or df[‘column’].mean()\nmedian - df.median() or df[‘column’].median()\nmode - df.mode() or df[‘column’].mode()\nstd - df.std() or df[‘column’].std()\nz-score - (df[‘column’] - df[‘column’].mean()) / df[‘column’].std()\nhistorgrams\n\nimport matplotlib.pyplot as plt\nplt.hist(variable, bins)"
  },
  {
    "objectID": "slides/10-data-descriptors.html#class-activity",
    "href": "slides/10-data-descriptors.html#class-activity",
    "title": "Week 10: Data Descriptors",
    "section": "Class Activity",
    "text": "Class Activity\n\nStats Intro Activity"
  },
  {
    "objectID": "slides/06-data-gathering.html#goals",
    "href": "slides/06-data-gathering.html#goals",
    "title": "Week 6: Data Gathering",
    "section": "Goals",
    "text": "Goals\n\n\nWhat types of data can you gather?\nWhat sources can data come from?\nHow is data stored (for CMPSC 105)?"
  },
  {
    "objectID": "slides/06-data-gathering.html#data-types-1",
    "href": "slides/06-data-gathering.html#data-types-1",
    "title": "Week 6: Data Gathering",
    "section": "Data Types",
    "text": "Data Types\n\n\nand numerical discrete!"
  },
  {
    "objectID": "slides/06-data-gathering.html#categorical-nominal",
    "href": "slides/06-data-gathering.html#categorical-nominal",
    "title": "Week 6: Data Gathering",
    "section": "Categorical Nominal",
    "text": "Categorical Nominal\n\n\nName only, qualitative\n\ncar makes\nzip code\neye color\n\nDichotomous variable refers to a categorical nominal variables with only two values\n\nleft handed / right handed\ncurrent student / non student"
  },
  {
    "objectID": "slides/06-data-gathering.html#categorical-ordinal",
    "href": "slides/06-data-gathering.html#categorical-ordinal",
    "title": "Week 6: Data Gathering",
    "section": "Categorical Ordinal",
    "text": "Categorical Ordinal\n\n\nordered, quasi-quantitative\n\nagreement level\neducation level\n\nordinal data can seem almost quantitative, but there is no way to know the value of the levels\nordinal scales are usually used to measure non-numeric features like happiness, customer satisfaction\nLikert Items are often used to obtain categorical ordinal data"
  },
  {
    "objectID": "slides/06-data-gathering.html#likert-items",
    "href": "slides/06-data-gathering.html#likert-items",
    "title": "Week 6: Data Gathering",
    "section": "Likert Items",
    "text": "Likert Items"
  },
  {
    "objectID": "slides/06-data-gathering.html#numerical-data",
    "href": "slides/06-data-gathering.html#numerical-data",
    "title": "Week 6: Data Gathering",
    "section": "Numerical Data",
    "text": "Numerical Data\n\n\nNumerical data are quantitative\nDiscrete means countable\n\nnumber of students\nnumber of views or likes"
  },
  {
    "objectID": "slides/06-data-gathering.html#numerical-data-1",
    "href": "slides/06-data-gathering.html#numerical-data-1",
    "title": "Week 6: Data Gathering",
    "section": "Numerical Data",
    "text": "Numerical Data\n\n\nNumerical data are quantitative\nContinuous means measured\n\nheight must be measured\nInterval refers to continuous data with no reference point\n\ntemperature, we know 28 F vs 33 F is a difference of 5, but does a difference of 5 mean the same thing between 100 and 105?\nInterval data cannot be divided meaningfully. Don’t compute what is 1/5 of the temperature today\nStats use division, causing a problem for interval data\n\nRatio refers to continuous data with a reference point\n\nHeight, weight, distance, speed\ndivision or other ratios are meaningful. Professor Luman is twice my height!"
  },
  {
    "objectID": "slides/06-data-gathering.html#practice",
    "href": "slides/06-data-gathering.html#practice",
    "title": "Week 6: Data Gathering",
    "section": "Practice",
    "text": "Practice\nRecall an example for each data type\n\n\nand numerical discrete!\n\nhttps://forms.gle/rqqcmMtnEHc6g3276"
  },
  {
    "objectID": "slides/06-data-gathering.html#data-acquisition",
    "href": "slides/06-data-gathering.html#data-acquisition",
    "title": "Week 6: Data Gathering",
    "section": "Data Acquisition",
    "text": "Data Acquisition\nGetting brand new data using surveys and sensors!"
  },
  {
    "objectID": "slides/06-data-gathering.html#surveys-for-acquisition",
    "href": "slides/06-data-gathering.html#surveys-for-acquisition",
    "title": "Week 6: Data Gathering",
    "section": "Surveys for Acquisition",
    "text": "Surveys for Acquisition\n\n\nsurveys are directed toward people\nsurveys answer subjective perceptual and behavioral questions, primarily\ndifferent questions produce different data types\n\nmultiple choice questions\nfree response questions\nslider ratings\nLikert scales"
  },
  {
    "objectID": "slides/06-data-gathering.html#surveys-for-acquisition-1",
    "href": "slides/06-data-gathering.html#surveys-for-acquisition-1",
    "title": "Week 6: Data Gathering",
    "section": "Surveys for Acquisition",
    "text": "Surveys for Acquisition\n\n\nSurvey development should be guided by a hypothesis\nOnly questions that have appropriate data types for analysis should be used\nQuality controls should be in place (e.g. timestamps, inclusion criteria)\nData security protocols should be in place to protect private data\nHuman Subjects Research must be reviewed by the Institutional Review Board\n\n\n\nReading: Surveys"
  },
  {
    "objectID": "slides/06-data-gathering.html#sensors-for-acquisition",
    "href": "slides/06-data-gathering.html#sensors-for-acquisition",
    "title": "Week 6: Data Gathering",
    "section": "Sensors for Acquisition",
    "text": "Sensors for Acquisition\n\n\nsensors can measure inanimate objects/materials or people/animals\nelectronic sensors for things\n\nmotion detection\nfreezer thermometer\ntire pressure sensor\n\nsensors for people\n\nmotion capture\nbody temperature\nelectro-physiological\n\nECG - electrocardiogram\nEEG - electroencephalogram\nelectrodermal"
  },
  {
    "objectID": "slides/06-data-gathering.html#sensors-for-acquisition-1",
    "href": "slides/06-data-gathering.html#sensors-for-acquisition-1",
    "title": "Week 6: Data Gathering",
    "section": "Sensors for Acquisition",
    "text": "Sensors for Acquisition"
  },
  {
    "objectID": "slides/06-data-gathering.html#acquisition-drawbacks",
    "href": "slides/06-data-gathering.html#acquisition-drawbacks",
    "title": "Week 6: Data Gathering",
    "section": "Acquisition Drawbacks",
    "text": "Acquisition Drawbacks\n\n\ntime consuming\ndata management is required (persistent storage, security)\nmaybe the data already exist somewhere\nmaybe surveys and sensors cannot answer the question you have"
  },
  {
    "objectID": "slides/06-data-gathering.html#extracting-data-from-documents",
    "href": "slides/06-data-gathering.html#extracting-data-from-documents",
    "title": "Week 6: Data Gathering",
    "section": "Extracting Data from Documents",
    "text": "Extracting Data from Documents\n\n\nDocuments often contain information but it is not in an analyzable format\n\nAuthor names on research papers\nForeground of an image\nBackground of an image\nVideo transcripts of speech\nVideo transcripts of sounds\nCells (biology) appearing in images\nLanguage structure\n\nnoun, verb, adj, conjunction,\nword length\nnum vowels\nnum syllables\netc"
  },
  {
    "objectID": "slides/06-data-gathering.html#extracting-data-by-web-scraping",
    "href": "slides/06-data-gathering.html#extracting-data-by-web-scraping",
    "title": "Week 6: Data Gathering",
    "section": "Extracting Data by Web Scraping",
    "text": "Extracting Data by Web Scraping\n\n\nScraping is gathering data form websites by reading into the html structure to get the content out of specific html tagged elements.\nScraping tools exist to assist with formatting\n\nRequests, BeautifulSoup, Selenium\nexample with https://en.wikipedia.org/wiki/Tadasu_no_Mori\n\n\n\n\nimport requests\n# Making a GET request\nr = requests.get('https://en.wikipedia.org/wiki/Tadasu_no_Mori')\n# print content of request\nprint(r.content)"
  },
  {
    "objectID": "slides/06-data-gathering.html#extracting-data-storage",
    "href": "slides/06-data-gathering.html#extracting-data-storage",
    "title": "Week 6: Data Gathering",
    "section": "Extracting Data & Storage",
    "text": "Extracting Data & Storage\n\n\nextracted data must be entered into usable structures\n\ndatabases\nspreadsheets\nplain text files"
  },
  {
    "objectID": "slides/06-data-gathering.html#drawbacks-of-extracting-data",
    "href": "slides/06-data-gathering.html#drawbacks-of-extracting-data",
    "title": "Week 6: Data Gathering",
    "section": "Drawbacks of Extracting Data",
    "text": "Drawbacks of Extracting Data\n\n\ndata entry is time consuming\ndata should be consistent, but real data is never perfect, so compromises must be made\nhuman errors can be difficult to detect\ndata entry done with automated entry tools is hard to validate\nvalidation takes human time, or accepted inaccuracy\narbitrary decisions may have to be made"
  },
  {
    "objectID": "slides/06-data-gathering.html#sources-of-pre-existing-data",
    "href": "slides/06-data-gathering.html#sources-of-pre-existing-data",
    "title": "Week 6: Data Gathering",
    "section": "Sources of Pre-existing Data",
    "text": "Sources of Pre-existing Data\n\n\nTableau Data\nOthers"
  },
  {
    "objectID": "slides/06-data-gathering.html#drawbacks-of-pre-existing-data",
    "href": "slides/06-data-gathering.html#drawbacks-of-pre-existing-data",
    "title": "Week 6: Data Gathering",
    "section": "Drawbacks of Pre-existing Data",
    "text": "Drawbacks of Pre-existing Data\n\n\nEthical collection practices may or may not have been used\ndata have been used repeatedly in explorations leading to bias and overfitting on the data across explorations\nmaybe the pre-existing data cannot answer the question you have"
  },
  {
    "objectID": "slides/06-data-gathering.html#csv",
    "href": "slides/06-data-gathering.html#csv",
    "title": "Week 6: Data Gathering",
    "section": "CSV",
    "text": "CSV\n\n\nComma-separated values format\nplain text file\n\nreadable and writable in many software programs\n\nGoogle Sheets\nMS excel\nNotepad\nSublime Text\nVS Code\n\n\n\n\n\nReading CSV Section 2.4 & 2.4.1"
  },
  {
    "objectID": "slides/06-data-gathering.html#csv-activity",
    "href": "slides/06-data-gathering.html#csv-activity",
    "title": "Week 6: Data Gathering",
    "section": "CSV Activity",
    "text": "CSV Activity\nMake a CSV file based on this one image to explore this open question: Are healthy foods too expensive?\n\nHow many different things can you imaging recording off of this one image?!"
  },
  {
    "objectID": "slides/06-data-gathering.html#csv-activity-details",
    "href": "slides/06-data-gathering.html#csv-activity-details",
    "title": "Week 6: Data Gathering",
    "section": "CSV Activity Details",
    "text": "CSV Activity Details\nStart a Google Sheet. Include:\n\nStore Name\nDate\nTime\nLocation\nTotal number of items purchased\nTotal number of non-food items purchased\nTotal amount of “health” foods\nTotal cost in USD\nTotal cost of “health” foods\nTotal cost of non-food items"
  },
  {
    "objectID": "slides/06-data-gathering.html#submit-your-work-to-your-activities-repo",
    "href": "slides/06-data-gathering.html#submit-your-work-to-your-activities-repo",
    "title": "Week 6: Data Gathering",
    "section": "Submit your work to your Activities Repo",
    "text": "Submit your work to your Activities Repo\nUse the name “data-gathering-activity.csv”"
  },
  {
    "objectID": "slides/06-data-gathering.html#end",
    "href": "slides/06-data-gathering.html#end",
    "title": "Week 6: Data Gathering",
    "section": "End",
    "text": "End"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "",
    "text": "Class Sessions: TuTh 9:30 AM-10:45 AM, Alden 101\nLaboratory Session: Th, 2:30 PM-4 PM, Alden 101\nInstructor: Professor Emily Graber, egraber@allegheny.edu\nOffice Location: Alden Hall 106\nOffice Hours: Visit Google Calendar to reserve an appointment as needed."
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Course Description",
    "text": "Course Description\nAn introduction to the methods of collecting, exploring, transforming and visualizing data for storytelling. Often participating in team-based and hands-on activities, students learn how to use web platforms and dashboards to acquire, explore and investigate data to generate summarized key data insights using visual techniques. Students also apply open-source programming language to discover patterns in the data, test hypotheses, and check assumptions using graphical representations. During a weekly laboratory session, students employ cutting-edge software tools to complete projects, reporting on their results through both written documents and oral presentations. Students are invited to use their own departmentally approved laptop in this course; a limited number of laptops are available for use during class and lab sessions.\nPrerequisite: None\nDistribution Requirements: QR, SP.\nDR tag rationale: This course will primarily focus on methods of data collection, foundational data analysis of numerical data, and visualizations of such data. Additionally, students will participate in the scientific process during the exploratory data analysis and apply scientific reasoning to analyze and synthesize data.\n\nLearning Outcomes\n\nDevelop hypotheses based on motivating problems and/or observations and identify appropriate data to address hypotheses.\nIdentify and describe key elements in different types of data visualizations.\nUse web-based platforms to accurately present data sets through multiple visualizations.\nUse an open-source programming language to compute summary statistics and visualize key patterns in the data.\nContribute to and present structured, web-based documentation that describes data exploration steps and visualization-based conclusions.\n\n\n\nScientific Process and Knowledge (SP)\n\nCourses involving Scientific Process and Knowledge aim to convey an understanding of what is known or can be known about the natural world; apply scientific reasoning towards the analysis and synthesis of scientific information; and create scientifically literate citizens who can engage productively in problem solving.\nLearning Outcome: Students who successfully complete this requirement will demonstrate an understanding of the nature, approaches, and domain of scientific inquiry.\n\n\n\nQuantitative Reasoning (QR)\n\nQuantitative Reasoning is the ability to understand, investigate, communicate, and contextualize numerical, symbolic, and graphical information towards the exploration of natural, physical, behavioral, or social phenomena.\nLearning Outcome: Students who successfully complete this requirement will demonstrate an understanding of how to interpret numeric data and/or their graphical or symbolic representations."
  },
  {
    "objectID": "index.html#schedule-at-a-glance",
    "href": "index.html#schedule-at-a-glance",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Schedule at-a-glance",
    "text": "Schedule at-a-glance\nWelcome\n\nWeek One: January 14, 16: Setup\n\nData Display\n\nWeek Two: January 21, 23: Display Types and Anatomy of a Chart\nWeek Three: January 28, 30: Data Distortion\nWeek Four: February 4, 7: Data Filtering\nWeek Five: February 11, 13: Interactive Display\n\nData Gathering\n\nWeek Six: February 18, 20: Turning Anything Into Data \nWeek Seven: February 25, 27: Web Data Analytics and Scraping\nSpring Break: March 1-9\nWeek Nine: March 11, 13: Data Wrangling\n\nData Processing\n\nWeek Ten: March 18, 20: Statistics Intro\nWeek Eleven: March 25, 27: Inferential Statistics\nWeek Twelve: April 1, 3: Comparing and Modeling\nWeek Thirteen: April 8: Clustering\n\nData Storytelling\n\nWeek Fourteen: April 15, 17: Storytelling Challenge\nWeek Fifteen: April 22, 24: Project Preparation\nWeek Sixteen: April 29: No Class Meeting\n\nFinal Presentations Code C\n\nThursday, May 1st, 2025 at 7:00 PM: Final Project Lightning Talks\n\nComplete Final Exam Schedule"
  },
  {
    "objectID": "index.html#grading",
    "href": "index.html#grading",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Grading",
    "text": "Grading\n\n\n\nAssignment type\nPercentage\n\n\n\n\nLabs\n50%\n\n\nParticipation\n30%\n\n\nFinal Project\n20%\n\n\n\nGrading policy may change as needed during the term; any changes will be announced to the class at the time of the change. Grades will be communicated via Canvas. Please note that attendance policies may additionally affect grades as adjustments to grades will be applied on top of the base grade according to policy\n\nLabs\nThere are 8 labs during the semester. Due dates are hard deadlines. See below for policy on late work.\nThe deliverables for labs include documentation in a GitHub repo addressing specific questions or demonstrating requested calculations, analyses, visualizations, and code snippets.\nLabs will be graded for having clean work with few careless errors, correct Markdown, code, data, correct images given the context of the lab, and correct explanations of concepts in writing\n\n\nParticipation\nParticipation in class work, group activities, and Discord are required. Documentation of in-class participation must be submitted by each student and cannot be made up. Participation on the Discord server can occur throughout each week. Each student is required to post at least once per week by asking either asking a real question or answering a question asked by your classmate. Collegial conversations about course topics or activities are also allowed.\nYou will have access to a repository for submitting all of your class activities. Each activity that you do in class will contribute to your overall participation grade. There is no grading scheme for class activities. I will simply check that the activity was turned in at the end of the class period, and that you have made an effort to do the activity as intended, and figures are showing.\nIf the activity is not turned in at the end of the class period, then it will not be counted toward your participation grade.\n\n\nFinal Project\nThe final project will be open ended. Techniques and skills learned throughout the course should be demonstrated in the project in a final presentation (included in the final project grade). The project must be approved by the teaching team in an initial stage. The artifact can be detailed blog post, following the format of the last lab, or a detailed data visualization with interactive visuals."
  },
  {
    "objectID": "index.html#policies",
    "href": "index.html#policies",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Policies",
    "text": "Policies\n\nAttendance\nStudents are expected to come to class prepared, on time, and to stay engaged for the duration of the class period. This includes both class and lab sessions. This behavior is core to our shared departmental values and is in addition to the college’s attendance policy.\n\nPreparedness\nComing to class prepared means coming with everything you need to engage in a class session. To satisfy basic expectations of CIS courses, this means, at minimum, that students must:\n\narrive at class with a fully charged laptop\nbring their laptop charger or a battery pack so as to ensure that their laptop works throughout the entire class session\ncomplete any pre-session work such as readings and preparatory assignments\n\n\n\nAttendance and Lateness\nOne missed class or lab session counts as one absence. Coming to class/lab late, leaving early, or missing a large portion of a class/lab session will result in your being marked as “late” to class. Coming to class/lab unprepared may also result in being marked “late”. Being marked “late” to class three times during the course of a semester is equal to one absence.\nStudents can have five absences without any impact to their grade. These accommodations are meant to cover illness and emergency, so you should always come to class if you are able to do so.\nAs a general guideline, students cannot miss more than two weeks of class in total throughout the academic semester without receiving a letter grade reduction.\nFor this course, excluding the first week and five excused absences, overall course grade will go down by 1/3 of a letter grade for each additional absence or absence equivalence regardless of base grade.\n\n\nEngagement\nThe term “engagement” or our expectation that students remain “engaged” can mean many things, often varying by course. Baseline behaviors that indicate engagement include:\n\nparticipation in class activities and discussions\ndefined contribution to class sessions in full-class or group discussions\nnote-taking (physical or digital)\nparticipating in course session attendance requirements\nnot participating in non-course related activities\nnot completing non-course related projects\n\n\n\n\nLate Work Policy\nThe deadlines for assignments are hard deadlines. This policy is intended to ensure that students keep up with course topics, are able to actively participate in class, and are accountable for managing time effectively.\nAll students in the CIS department are expected to turn in assignments on time. “On time” means on or before the assignment’s due date. This means that an assignment cannot be turned in for credit after a due date, unless the student applies a token.\n\nTokens\nStudents in 105 are allotted four tokens to receive extensions on any assignment except the final with no questions asked by the course instructor except either in the rare cases of documented severe and/or extenuating circumstances or in cases that violate the CIS policy document or any College-approved policy.\nA token may be applied via a Google Form up to the assignment deadline, with exceptions granted only for severe and/or extenuating circumstances.\nTokens grant an automatic extension of one week to anything except the final exam.\nToken Form for Automatic Extension\n\n\n\nExtenuating Circumstances\nExtenuating circumstances are exceptional, unforeseen, outside of your control, and short-term, like illness and emergency. Regular circumstances associated with taking courses at Allegheny College are not considered extenuating.\nThe accommodations provided by tokens and permitted absences are meant to cover extenuating circumstances like illness, emergency, and work. However, if you have a contagious illness like COVID-19, the flu, or a cold, you should not come to class. If you have expended all your absences and tokens and are still sick with a contagious illness, you may contact your professor about options. If your symptoms are mild or you are recovering from a respiratory illness, we recommend that you wear a mask to class.\nProfessor must be informed of all athletic obligations at the beginning of the semester, or with as much notice as possible. If you are feeling healthy and well, you should make every effort to come to class on time and to complete assignments, rather than using absences and tokens you may need later.\nThese no-questions-asked accommodations are meant to protect student privacy, and to remove the additional effort of acquiring documentation under duress of illness or emergency. In addition, they allow the professor to remain focused on teaching rather than adjudicating excuses.\nIf extenuating circumstances are severe enough to require more absences and tokens, you may contact your professor to discuss options. In most cases, however, a situation of this gravity warrants a request for a “Late Drop” or “Incomplete” in the course, as the student will not have had adequate opportunity to learn the material."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Resources",
    "text": "Resources\n\nFundamentals of Data Visualization\n\nFull Text\n\nMaking Sense of Data by Glenn J. Myatt and Wayne P. Johnson\n\nI. Exploratory Data Analysis\nII. Data Visualization\nIII. Interactive Visualizations\n\nNaked statistics: stripping the dread from the data by Charles J. Wheelan\n\nGoogle Preview\n\nNatural Resources Biometrics by Diane Kiarnan\n\nFull Text\n\nPython Data Science Handbook by Jake VanderPlas\n\nFull Text\n\nPython for Data Analysis, 3E by Wes McKinney\n\nFull Text\n\nArticles\n\nVariable Types"
  },
  {
    "objectID": "index.html#communications",
    "href": "index.html#communications",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Communications",
    "text": "Communications\n\nUsing GitHub and Discord\nThis course will primarily use GitHub and Discord for collaborative course communication. Communications that are not private matters must take place in the Data Exploration Channel in Discord.\nThe Allegheny College Computer and Information Science Discord Server will also have useful announcements about departmental activities including TL office hours.\n\n\nUsing Email\nAlthough we will primarily use Discord for class communication, the course instructor will sometimes use email to send announcements about important matters such as changes in the schedule. It is your responsibility to check your email at least once a day and to ensure that you can reliably send and receive emails."
  },
  {
    "objectID": "index.html#honor-code",
    "href": "index.html#honor-code",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Honor Code",
    "text": "Honor Code\nThe Academic Honor Program that governs the entire academic program at Allegheny College is described in the Allegheny Academic Bulletin. The Honor Program applies to all work that is submitted for academic credit or to meet non-credit requirements for graduation at Allegheny College. This includes all work assigned for this class (e.g., examinations and course assignments). All students who have enrolled in the College will work under the Honor Program. Each student who has matriculated at the College has acknowledged the following Honor Code pledge:\n\nI hereby recognize and pledge to fulfill my responsibilities, as defined in the Honor Code, and to maintain the integrity of both myself and the College community as a whole.\n\n\nEffective Collaboration\nComputer science is an inherently collaborative discipline. The Department of Computer and Information Science at Allegheny College encourages students to engage in collaboration. However, in the context of individual coursework, through which each student must demonstrate their own knowledge, there are certain forms of collaboration that are and are not acceptable.\n\nAcceptable forms of collaboration include:\n\nDiscussing high-level concepts.\nReferring someone to a course text book, course slides, example programs, or other resources that contain helpful information or instructions.\nOutlining the high-level steps to solving a problem, without mentioning specific\nlines of code that need to be written.\n\nUnacceptable forms of collaboration include:\n\nSharing details about specific lines of code, including showing your source code to someone or looking at someone else’s code.\nCopying someone else’s source code, technical writing, program commands, or program output, even with some slight modifications.\nTyping source code, technical writing, or commands on someone else’s computer.\n\n\n\n\nPlagiarism and Artificial Intelligence\nStudents may not pass off or represent the work of another student, or their own prior work, as their own current work in any case. Plagiarism and AI-generatated code, text, or images are not permitted in any assignment type unless the instructions supplied for the assignment explicitly state otherwise.For exams and all other coursework, students are expected to adhere to the given instructions for the particular exam or item of coursework. It is the responsibility of the student to review the authorization specifications on every item and act appropriately, upholding the honor code. Suspected plagiarized or unauthorized use of AI to generate the work that is turned in will be reported to the Honor Code Committee. This policy does not preclude the use of AI to learn."
  },
  {
    "objectID": "index.html#educational-accommodations",
    "href": "index.html#educational-accommodations",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Educational Accommodations",
    "text": "Educational Accommodations\nThe Americans with Disabilities Act (ADA) is a federal anti-discrimination statute that provides comprehensive civil rights protection for persons with disabilities. Among other things, this legislation requires all students with disabilities be guaranteed a learning environment that provides for reasonable accommodation of their disabilities. Students with disabilities who believe they may need accommodations in this class are encouraged to contact Student Accessibility and Support Services (SASS) at 814-332-2898. Student Accessibility and Support Services is part of the Learning Commons and is located in Pelletier Library. Please do this as soon as possible to ensure that approved accommodations are implemented in a timely fashion."
  },
  {
    "objectID": "index.html#syllabus-changes",
    "href": "index.html#syllabus-changes",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Syllabus Changes",
    "text": "Syllabus Changes\nThe instructor may make updates or changes to this document at any time as needed until term grades are due. Changes will be announced to the class."
  },
  {
    "objectID": "code/20250317_testing_debugging.html",
    "href": "code/20250317_testing_debugging.html",
    "title": "Guttag Chapter 8",
    "section": "",
    "text": "Open In Colab\n\n\n\nGuttag Chapter 8\n\n# Example function within palindromechecker.palindrome\n\n# TODO: what is the module name?\n# TODO: what is the package name?\n# TODO: does the function def within the module rely on any imported objects?\n\ndef pal_rev(word: str) -&gt; bool:\n  \"\"\"Determine if a given word is a palindrome.\"\"\"\n  # TODO: reverse the word\n  # TODO: return whether or not the reversed word is the same as the word\n\n\n# Example function within palindromechecker.palindrome\n\n# TODO: what is the module name?\n# TODO: what is the package name?\n# TODO: does the function def within the module rely on any imported objects?\n\ndef pal_rev(word: str) -&gt; bool:\n  \"\"\"Determine if a given word is a palindrome.\"\"\"\n  return word == word[::-1]\n\n\n# Example function within tests.test_palindrome\n\n# TODO: what is the module name?\n# TODO: what is the package name?\n# TODO: does the function def within the module rely on any imported objects?\n\ndef test_short_not_palindrome_word_reverse():\n    \"\"\"Ensure that a short word of \"taylor\" does not work correctly with reverse.\"\"\"\n    # TODO: hard code the input\n    # TODO: hard code the expected answer\n    # TODO: call the function under test with the hard coded input\n    # TODO: make sure the return value is saved!\n    # TODO: use the assert syntax compare the hard coded expected answer with\n    # the returned answer\n\n\ndef test_short_not_palindrome_word_reverse():\n    \"\"\"Ensure that a short word of \"taylor\" does not work correctly with reverse.\"\"\"\n    test_word = 'taylor' # hard coded\n    expected_result = False # hard coded\n    result = pal_rev(test_word)\n    assert result == expected_result"
  },
  {
    "objectID": "code/data_distortion_activity.html",
    "href": "code/data_distortion_activity.html",
    "title": "Class Activity",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_distortion_activity.html#goals",
    "href": "code/data_distortion_activity.html#goals",
    "title": "Class Activity",
    "section": "Goals",
    "text": "Goals\n\nWork with colleagues at your table\nLook at code that can distort data displays\nModify code to distort data displays\nDescribe how data distortion can imply information that was not in raw data\n\n\n\nCode\n# TODO All Tables: Run this code cell that makes pre-existing tools available for data exploration\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n\nCode\n# TODO All Tables: Run this code cell that creates a pandas dataframe\n\ndf = pd.read_csv(\n    'https://raw.githubusercontent.com/allegheny-college-cmpsc-105-spring-2025/site/main/data/data-distortion-bls-LNS14000000.csv',\n    sep=',',\n    names = ['Timepoint', 'Year', 'Month', 'Label', 'Value'],\n    skiprows=1\n)\n\nprint(df.head()) # Display the first few rows of the DataFrame\n\n\n\n\nCode\n- TODO: In the variable explorer (`{x}`), what Shape does the variable `df` have? Write your response here:"
  },
  {
    "objectID": "code/data_distortion_activity.html#table-1",
    "href": "code/data_distortion_activity.html#table-1",
    "title": "Class Activity",
    "section": "Table 1",
    "text": "Table 1\n\n\nCode\n# TODO: Run this code cell that creates a line graph of the data\n\n# Assuming df is already created in the previous code cell\nplt.close('all')\n\nplt.figure(figsize=(12, 4))\nplt.plot(df['Timepoint'], df['Value'], '*-')\nplt.xticks(df['Timepoint'][::12], df['Label'][::12], rotation=0)\nplt.xlabel('Timepoint (Years)')\nplt.ylabel('Unemployment Rate (%)')\nplt.title('Unemployment Rate Year to Year')\nplt.grid(True)\nplt.xlim(20,40)\nplt.ylim(3,8)\nplt.show()\n\n\n\nTODO: What does this figure show?"
  },
  {
    "objectID": "code/data_distortion_activity.html#table-2",
    "href": "code/data_distortion_activity.html#table-2",
    "title": "Class Activity",
    "section": "Table 2",
    "text": "Table 2\n\n\nCode\n# TODO: Run this code cell that creates a line graph of the data\n\n# Assuming df is already created in the previous code cell\nplt.close('all')\n\nplt.figure(figsize=(6, 2))\nplt.plot(df['Timepoint'], df['Value'], '*-')\nplt.xticks(df['Timepoint'][::12], df['Label'][::12], rotation=0)\nplt.xlabel('Timepoint (Years)')\nplt.ylabel('Unemployment Rate (%)')\nplt.title('Unemployment Rate Year to Year')\nplt.grid(True)\nplt.xlim(20,40)\nplt.ylim(0,100)\nplt.show()\n\n\n\nTODO: What does this figure show?"
  },
  {
    "objectID": "code/data_distortion_activity.html#table-3",
    "href": "code/data_distortion_activity.html#table-3",
    "title": "Class Activity",
    "section": "Table 3",
    "text": "Table 3\n\n\nCode\n# TODO: Run this code cell that creates a line graph of the data\n\n# Assuming df is already created in the previous code cell\nplt.close('all')\n\nplt.figure(figsize=(3, 6))\nplt.plot(df['Timepoint'], df['Value'], '*-')\nplt.xticks(df['Timepoint'][::12], df['Label'][::12], rotation=0)\nplt.xlabel('Timepoint (Years)')\nplt.ylabel('Unemployment Rate (%)')\nplt.title('Unemployment Rate Year to Year')\nplt.grid(True)\nplt.xlim(20,40)\nplt.ylim(0,100)\nplt.show()\n\n\n\nTODO: What does this figure show?"
  },
  {
    "objectID": "code/data_distortion_activity.html#table-4",
    "href": "code/data_distortion_activity.html#table-4",
    "title": "Class Activity",
    "section": "Table 4",
    "text": "Table 4\n\n\nCode\n# TODO: Run this code cell that creates a line graph of the data\n\n# Assuming df is already created in the previous code cell\nplt.close('all')\n\nplt.figure(figsize=(3, 9))\nplt.plot(df['Timepoint'], df['Value'], '*-')\nplt.xticks(df['Timepoint'][::12], df['Label'][::12], rotation=0)\nplt.xlabel('Timepoint (Years)')\nplt.ylabel('Unemployment Rate (%)')\nplt.title('Unemployment Rate Year to Year')\nplt.grid(True)\nplt.xlim(20,40)\nplt.ylim(3,8)\nplt.show()\n\n\n\nTODO: What does this figure show?"
  },
  {
    "objectID": "code/data_distortion_activity.html#discussion",
    "href": "code/data_distortion_activity.html#discussion",
    "title": "Class Activity",
    "section": "Discussion",
    "text": "Discussion\nShare your observations\n\nWhat did the plot at your table show?\nWhat is the best representation of the data?"
  },
  {
    "objectID": "code/data_distortion_activity.html#technical-exploration",
    "href": "code/data_distortion_activity.html#technical-exploration",
    "title": "Class Activity",
    "section": "Technical Exploration",
    "text": "Technical Exploration\n\nWhat new python expressions do you see in the code?\nTry changing them below to see what happens\n\n\n\nCode\n# TODO: Run this code cell that creates a line graph of the data\n# TODO: Change the xlim, ylim, and figsize to see what happens\n\n# TODO: try plt.xlim(800,900)\n# TODO: adjust the ylim so that the line does not go off the canvas\n# TODO: change the figsize to make a tall, skinny canvas\n\n# Assuming df is already created in the previous code cell\nplt.close('all')\n\nplt.figure(figsize=(10,6))\nplt.plot(df['Timepoint'], df['Value'], '*-')\nplt.xticks(df['Timepoint'][::12], df['Label'][::12], rotation=45)\nplt.xlabel('Timepoint (Years)')\nplt.ylabel('Unemployment Rate (%)')\nplt.title('Unemployment Rate Year to Year')\nplt.grid(True)\nplt.xlim(20,40)\nplt.ylim(3,8)\nplt.show()"
  },
  {
    "objectID": "code/data_distortion_activity.html#closing-thoughts",
    "href": "code/data_distortion_activity.html#closing-thoughts",
    "title": "Class Activity",
    "section": "Closing Thoughts",
    "text": "Closing Thoughts\n\nTODO: Describe how data distortion can imply things that were not in raw data\nTODO: How could daily life be impacted by distorted data?"
  },
  {
    "objectID": "code/linear_regression.html",
    "href": "code/linear_regression.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/linear_regression.html#song-popularity-dataset",
    "href": "code/linear_regression.html#song-popularity-dataset",
    "title": "Data Exploration",
    "section": "Song Popularity Dataset",
    "text": "Song Popularity Dataset\n\n\nCode\nimport pandas as pd\n\ndf = pd.read_csv('https://raw.githubusercontent.com/allegheny-college-cmpsc-105-spring-2025/site/refs/heads/main/data/data-analysis-kaggle-song-popular.csv')\ndf\n\n\n\nTODO: In the variable explorer ({x}), what Shape does the variable df have? Write your response here:"
  },
  {
    "objectID": "code/linear_regression.html#visualize",
    "href": "code/linear_regression.html#visualize",
    "title": "Data Exploration",
    "section": "Visualize",
    "text": "Visualize\n\n\nCode\nimport matplotlib.pyplot as plt\n\npop = df.song_popularity\ndur = df.song_duration_ms/(60 * 1000) # duration in minutes\n\nplt.figure()\nplt.scatter(pop, dur)\nplt.xlabel('Popularity')\nplt.ylabel('Duration (minutes)')\nplt.show()"
  },
  {
    "objectID": "code/linear_regression.html#correlation",
    "href": "code/linear_regression.html#correlation",
    "title": "Data Exploration",
    "section": "Correlation",
    "text": "Correlation\n\n\nCode\npop = df.song_popularity\ndur = df.song_duration_ms/(60 * 1000) # duration in minutes\n\nnumerator = sum((pop - pop.mean()) * (dur - dur.mean()))\ndenominator = (sum( (pop - pop.mean())**2 ) * sum( (dur - dur.mean())**2 )) ** 0.5\n\nr = numerator / denominator\nprint(r)"
  },
  {
    "objectID": "code/linear_regression.html#slope",
    "href": "code/linear_regression.html#slope",
    "title": "Data Exploration",
    "section": "Slope",
    "text": "Slope\n\n\nCode\npop = df.song_popularity\ndur = df.song_duration_ms/(60 * 1000) # duration in minutes\n\nnumerator = sum((pop - pop.mean()) * (dur - dur.mean()))\ndenominator = (sum( (pop - pop.mean())**2 ))\n\nslope = numerator / denominator\nprint(slope)"
  },
  {
    "objectID": "code/linear_regression.html#intercept",
    "href": "code/linear_regression.html#intercept",
    "title": "Data Exploration",
    "section": "Intercept",
    "text": "Intercept\n\n\nCode\n# y = m * x + b\n# dur  = slope * pop + intercept\n# intercept = dur - slope * pop\n\nintercept = dur.mean() - (slope * pop.mean())\nprint(intercept)"
  },
  {
    "objectID": "code/linear_regression.html#add-line-to-figure",
    "href": "code/linear_regression.html#add-line-to-figure",
    "title": "Data Exploration",
    "section": "Add Line to Figure",
    "text": "Add Line to Figure\n\n\nCode\nplt.figure()\nplt.scatter(pop, dur)\nplt.xlabel('Popularity')\nplt.ylabel('Duration (minutes)')\n\nplt.plot([0, 100], [slope * 0 + intercept, slope * 100 + intercept], 'r')\nplt.show()"
  },
  {
    "objectID": "code/linear_regression.html#comparing-predicted-and-actual-y-values",
    "href": "code/linear_regression.html#comparing-predicted-and-actual-y-values",
    "title": "Data Exploration",
    "section": "Comparing Predicted and Actual y-values",
    "text": "Comparing Predicted and Actual y-values\n\n\nCode\npred_dur = slope * pop + intercept\nerror = pred_dur - dur # compare using subtraction\nMSE = (error ** 2).mean() # mean squared error\nprint(MSE)"
  },
  {
    "objectID": "code/linear_regression.html#using-scipy",
    "href": "code/linear_regression.html#using-scipy",
    "title": "Data Exploration",
    "section": "Using scipy",
    "text": "Using scipy\n\n\nCode\nimport scipy\n\nslope, intercept, r, p, se = scipy.stats.linregress(pop, dur)\n\n\n\n\nCode\nprint(slope)\nprint(intercept)\nprint(r)\nprint(p)\nprint(se)\n\n\n\n\nCode\nr, p = scipy.stats.pearsonr(pop, dur)\nprint(r)\nprint(p)\n\n\n\n\nCode\nr**2"
  },
  {
    "objectID": "code/data_display_activity.html",
    "href": "code/data_display_activity.html",
    "title": "Class Activity",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_display_activity.html#goals",
    "href": "code/data_display_activity.html#goals",
    "title": "Class Activity",
    "section": "Goals",
    "text": "Goals\n\nLook at code that can generate common data displays\nModify code that can generate common data displays\nDescribe how common data displays are able to convey information that was not apparent in raw data\n\n\nTODO: Run the first code cell\nTODO: In the variable explorer ({x}), what Type does the variable df have? Write your response here:\nTODO: In the variable explorer ({x}), what Shape does the variable df have? Write your response here:\nTODO: In the variable explorer ({x}), hover over the variable df to see the values. What relationship do the values have to the Shape of df? Explain what the shape means. Write your response here:\nTODO: Looking at the rest of the code cells that can generate figures, what patterns do you see repeated in the code? Write your response here:\nTODO: Run the code cells, stopping once you reach the next section. Examine the figures.\nTODO: Explain what relationship exists between the reddish code in quotes and the figures that are generated. Write your response here:\nTODO: Find a piece of code where a marker was explicitly specified. Change the marker to an upward triangle, a square, and a star based on the matplotlib documentation and rerun the code.\nTODO: Overall, do these figures reveal anything about this data that was not so apparent when looking at df? Write your response here:\nNow, move on to the next section\n\nThe data table below shows how many millions of prescriptions are obtained from various sources in the United States annually.\n\n\n\nDrug Source\nNum Prescriptions\n\n\n\n\nTraditional\n914\n\n\nIndependent\n666\n\n\nMassMerch\n238\n\n\nSuperMarket\n221\n\n\nMailOrder\n86\n\n\n\n\n\nCode\n# import pandas and make dataframe\n\nimport pandas as pd\n\ndata = {'Drug Source': ['Traditional', 'Independent', 'MassMerch', 'SuperMarket', 'MailOrder'],\n        'Num Prescriptions': [914, 666, 238, 221, 86]}\ndf = pd.DataFrame(data)\n\ndf\n\n\n\n\n\n\n\n\n\nDrug Source\nNum Prescriptions\n\n\n\n\n0\nTraditional\n914\n\n\n1\nIndependent\n666\n\n\n2\nMassMerch\n238\n\n\n3\nSuperMarket\n221\n\n\n4\nMailOrder\n86\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assuming df is already created in the previous code\nplt.figure()\nplt.scatter(df['Num Prescriptions'], df['Drug Source'])\nplt.xlabel('Number of Prescriptions')\nplt.ylabel('Drug Source')\nplt.title('Drug Source vs. Number of Prescriptions')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Assuming df is already created in the previous code\n\nplt.figure()\nplt.pie(df['Num Prescriptions'], labels=df['Drug Source'])\nplt.title('Drug Source')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Assuming df is already created in the previous code\n\nplt.figure()\nplt.hist(df['Num Prescriptions'], bins=20)\nplt.xlabel('Number of Prescriptions')\nplt.ylabel('Frequency')\nplt.title('Histogram of Number of Prescriptions')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Assuming df is already created in the previous code\nplt.figure()  # Adjust figure size for better visualization\nplt.plot(df['Drug Source'], df['Num Prescriptions'], marker='o', linestyle='-')\nplt.xlabel('Drug Source')\nplt.ylabel('Number of Prescriptions (Millions)')\nplt.title('Number of Prescriptions by Drug Source')\nplt.grid(True, linestyle='--', alpha=0.7)  # Add a grid for better readability\nplt.xticks(rotation=45) # Rotate x-axis labels for better visibility\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Assuming df is already created in the previous code\nplt.figure()\nplt.boxplot(df['Num Prescriptions'])  # Create the boxplot\nplt.xlabel('Number of Prescriptions')\nplt.title('Box Plot of Number of Prescriptions')\nplt.show()"
  },
  {
    "objectID": "code/data_filtering_activity.html",
    "href": "code/data_filtering_activity.html",
    "title": "Class Activity",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_filtering_activity.html#goals",
    "href": "code/data_filtering_activity.html#goals",
    "title": "Class Activity",
    "section": "Goals",
    "text": "Goals\n\nWork with colleagues at your table\nReview variables and assignment\nWrite code to control a matrix\nWrite code for logical contorl\nWrite code for dataframe control"
  },
  {
    "objectID": "code/data_filtering_activity.html#variables-and-assignment-ref",
    "href": "code/data_filtering_activity.html#variables-and-assignment-ref",
    "title": "Class Activity",
    "section": "Variables and Assignment (REF)",
    "text": "Variables and Assignment (REF)\n\n\nCode\n# Variables are names - a reusable label for a data value.\n\nname = 'Marc'\nprint(name)\npi = 3.14\nprint(pi)\ncustomer_id = \"1234\"\n# TODO: add a print statement to see customer_id\naccount_balance = 1000\n# TODO: add a print statement to see account_balance\n\n\n\n\nCode\n# if the same name is used to store new data, the old data is lost\n\npi = 3.14\nprint(pi)\npi = 'Marc'\n# TODO: add a print statement to see pi\n\n\n\n\nCode\n# assignment is a fancy term for associating or storing data\n\n# here 3.14 is assigned to the variable name pi using the `=`\npi = 3.14\n\n# TODO: assign the value 5 to pi\n# TODO: add a print statement to see pi\n# TODO: assign the value \"hello\" to message\n# TODO: add a print statement to see message\n# TODO: assign the value [1,2,3,4,5] to data\n# TODO: add a print statement to see data\n\n\n\nReserved Words\nThe following words have special meaning in Python. We call them keywords or reserved words and you may not use these names for your program variables.\n\nand, as, assert, async, await, break, class, continue, def, del, elif, else, except, False, finally, for, from, global, if, import, in, is, lambda, nonlocal, None, not, or, pass, raise, return, True, try, while, with, yield"
  },
  {
    "objectID": "code/data_filtering_activity.html#matrix",
    "href": "code/data_filtering_activity.html#matrix",
    "title": "Class Activity",
    "section": "Matrix",
    "text": "Matrix\n\n\nCode\n# TODO: run this code to make a simple matrix in a pandas dataframe\n\nimport pandas as pd\n\nmatrix = pd.read_csv(\n    '/content/data-filtering-matrix.csv',\n    sep=',',\n    names = ['A', 'B', 'C'],\n    skiprows=1)\n\n\n\n\nCode\n# TODO: add a print statement to see the dataframe\nprint(matrix)\n\n\n\n\nCode\n# The matrix contains 15 values in five rows and three columns\n# TODO: verify this using the data explorer\n\n\n# Each item has a unique location in the matrix given by its row and column\n# Using python convention, the rows and columns are idenfied with integers starting at 0!\n\n# On the 0th row, column 0 has the value of 0.0\n# On the 4nd row, column 0 has the value of 4.0\n# TODO: What is the largest row index in the matrix?\n# TODO: What is the largest column index in the matrix?\n\n# Here's how you access the element on row 4, column 0\nelement = matrix.iloc[4,0]\nprint(element)\n\n# TODO: access the element on row 3 column 2 and assign it to the variable `another_element`\n# TODO: add a print statement to see `another_element`\n\n# TODO: make sure you get what you expect!\n\n\n\n\nCode\n# Indexing to get one element is very simple, but what if you want multiple elements in a row, or in a column?\n\n# Slicing is the way to do it!\n# the sytax for slicing is like this: [start_index:end_index:hop_size]\n# Using python convention, note that the end_index will not be included in the slice\n\n# Here is a slice example on the columns\nslice_example = matrix.iloc[0,0:2:1]\nprint(slice_example)\n\n# TODO: use words to write out what the slice contains\n\n# TODO: Write a slice that gets the first through fourth rows (not including 4) from column two and assign it to a variable\n# TODO: add a print statement to see your slice\n\n# TODO: Write a slice that gets the 0th through fourth rows (not including 4) from column one, hopping by 2, and assign it to a variable\n# TODO: add a print statement to see your slice\n\n# TODO: Come up with your own example\n\n# TODO: make sure you get what you expect!\n\n\n\n\nCode\n# The syntax of a slice is [start:end:hop_size], but if start or end is left out, then the endpoints are assumed!\n# warning - don't forget to include the `:`\n\n# Here is every columns in row 0, including the start and INCLUDING the end!\nfull_slice = matrix.iloc[0,::1]\nprint(full_slice)\n\n# TODO: Write a slice that gets every column in row 4, including the start and INCLUDING the end! Assign to a variable\n# TODO: add a print statement to see your slice\n\n# TODO: make sure you get what you expect! Is there anything unexpected?\n\n\n\n\nCode\n# Slices to endpoints have already been used in our labs\n\n# TODO: find any spot where the slices have been used in our labs and put a link for yourself below\n# TODO: how was the slice used in the lab?"
  },
  {
    "objectID": "code/data_filtering_activity.html#logical-control",
    "href": "code/data_filtering_activity.html#logical-control",
    "title": "Class Activity",
    "section": "Logical Control",
    "text": "Logical Control\n\n\nCode\n# First lets review some comparison operators\n\n\nThe following table summarizes the most commonly used comparison operators in Python, along with their definition when applied to numbers.\n\n\n\noperator\noperation on numbers\n\n\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n\nAs their name suggests, comparison operators allow us to compare two values.\n\n\nCode\n# Here is a comparison of 4 vs 5. It asks the question: is four larger than five?\n# TODO: what answer should come out?\n# TODO: run this, what does come out?\n4 &gt; 5\n\n\n\n\nCode\n# As you can see, comparison operators allow us to compare values and result in a boolean type indicating whether the comparison is `True` or `False`.\n# TODO: make a comparison the checks if five is greater than four, assign to a variable and print it\n# TODO: make a comparison the checks if five is not equal to four, assign to a variable and print it\n# TODO: make a comparison the checks if five is equal to four, assign to a variable and print it\n\n\n\n\nCode\n# TODO: what is the difference between `=` and `==`?\n\n\n\n\nCode\n# It turns out that matrices can be compared too!\n# What elements in the matrix are greater than 1?\n\n# TODO: what do you think will happen\nselection = matrix &gt; 1\n# TODO: add a print statement to see selection\n# Does it match your expectations?\n\n\n\n\nCode\n# Write another comparison with matrix to ask which elements are equal to 4, assign to a variable called select_4 and print\n\n\n\n\nCode\n# Now we can use the selection to access only those elements!\n# The rows and columns do not need to be set.\n# Simply use the selection as the only index! Amazing!\n\nresult = matrix[selection]\nprint(result)\n\n# TODO: use select_4 as the only index, assign to variable and print\n# TODO: Does it match your expectations?\n\n\n\n\nCode\n# Finally, I want to show you how to combine comparions\n# Think of this question: what elements in the matrix are greater than one AND less then three?\n# The AND is done with `&`\n\ngreaterthanone = matrix &gt; 1\nprint(\"greather than one: \\n\", greaterthanone)\nlessthanthree = matrix &lt; 3\nprint(\"less than three: \\n\", lessthanthree)\nboth = greaterthanone & lessthanthree\nprint(\"both: \\n\", both)\nresult = matrix[both]\nprint(\"result: \\n\", result)\n\n# TODO: Does it match your expectations?\n\n\n\n\nCode\n# Here is the same thing, but all in one line of code...\n\nprint(matrix[(matrix &gt; 1) & (matrix &lt; 3)])\n\n\n\n\nCode\n# TODO: think of one or more questions you have and then post it in discord.\n# TODO: As you see your colleagues questions, reply to their message if you have the answer!"
  },
  {
    "objectID": "code/data_filtering_activity.html#dataframe-control-with-.loc",
    "href": "code/data_filtering_activity.html#dataframe-control-with-.loc",
    "title": "Class Activity",
    "section": "Dataframe Control with .loc",
    "text": "Dataframe Control with .loc\n\n\nCode\n# Controlling a Dataframe is similar to controlling a matrix.\n# Slicing is possible and logical comparison are possible!\n# One of the main differences is that indexing is done with .loc\n\n# Below is a the hourly temperature normals dataset for Meadville in a pandas dataframe called `dfm`\n# This same dataset was used in the data_distortion lab\n# The columns are named\n# The column containing the normals is called `HLY-TEMP-NORMAL`\n# Each hour is a year is given in the column called `INDEX`\n# A readable label for each hour in a year is given in the column called `DATE`\n\n# lets apply your new skills of logical indexing to this dataset\n\n\n\n\nCode\n# TODO: run this cell\n\n# load pre-existing tools available for data exploration\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# create a pandas dataframe\ndfm = pd.read_csv(\n    'https://raw.githubusercontent.com/allegheny-college-cmpsc-105-spring-2025/data-distortion-starter/refs/heads/main/data/data-distortion-noaa-2006-2020-USW00004843.csv',\n    sep=',',\n    names = ['INDEX', 'STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION',\n       'DATE', 'month', 'day', 'hour', 'HLY-TEMP-NORMAL'],\n    skiprows=1\n)\n\n# Display the first few rows of the DataFrame\nprint(dfm.head())\n\n\n\n\nCode\n# TODO: In the variable explorer (`{x}`), what Shape does the variable `dfm` have? Write your response here:\n# TODO: how many rows are in the dataframe?\n# TODO: how many columns are in the dataframe?\n\n\n\n\nCode\n# This cell creates logical filters, then applies them with .loc\n\n# Only rows from the midnight hour in the month of March are selected\nselected_hours = dfm['hour'] == 0\nselected_months = dfm['month'] == 3\nselected_rows = selected_hours & selected_months\n\n\n# new dataframes are made that contain ONLY THE SELECTED ROWS using .loc\n# here is the syntax for .loc: .loc[rows, columns]\ndfm_selected_normals = dfm.loc[selected_rows, 'HLY-TEMP-NORMAL']\ndfm_selected_indices = dfm.loc[selected_rows, 'INDEX']\ndfm_selected_dates = dfm.loc[selected_rows, 'DATE']\n\n\nprint(dfm_selected_normals)\nprint(dfm_selected_indices)\nprint(dfm_selected_dates)\n\n\n\n\nCode\n# Here is the same thing in one line\n\ndfm.loc[(dfm['hour'] == 0) & (dfm['month'] == 3), 'INDEX']\n\n\n\n\nCode\n# Assuming df is already created in the previous code cell\n\n# TODO: Run this code cell\n# TODO: What does the figure show?\n# TODO: Fill in appropriate title, xlabel and ylabel using you understanding of logical indexing\n\n# Control how many xtick labels are on the x axis\nxtick_hopsize = 3\n\n# Clear out memory (doesn't impact the visualization, but keeps the computer happy)\nplt.close('all')\n\n# make a blank canvas\nplt.figure(figsize=(12, 4))\n\n# set the overall title for all subfigures\nplt.suptitle('Figure 1')\n\n# subplot 1\nplt.subplot(1, 2, 1)\nplt.plot(dfm.loc[(dfm['hour'] == 7) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 7) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 1\nplt.plot(dfm.loc[(dfm['hour'] == 8) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 8) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 2\nplt.plot(dfm.loc[(dfm['hour'] == 9) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 9) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 3\nplt.plot(dfm.loc[(dfm['hour'] == 10) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 10) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 4\nplt.plot(dfm.loc[(dfm['hour'] == 11) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 11) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 5\nplt.plot(dfm.loc[(dfm['hour'] == 12) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 12) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 6\nplt.plot(dfm.loc[(dfm['hour'] == 13) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 13) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 7\nplt.plot(dfm.loc[(dfm['hour'] == 14) & (dfm['month'] == 2), 'INDEX'], dfm.loc[(dfm['hour'] == 14) & (dfm['month'] == 2), 'HLY-TEMP-NORMAL'], '*-') # layer 8\nplt.legend(['7 AM', '8 AM', '9 AM', '10 AM', '11 AM', '12 PM', '1 PM', '2 PM'])\n# the plt.xticks function labels the ticks so that dates appear instead of index\nplt.xticks(dfm.loc[(dfm['hour'] == 11) & (dfm['month'] == 2), 'INDEX'][::xtick_hopsize], dfm.loc[(dfm['hour'] == 11) & (dfm['month'] == 2), 'DATE'][::xtick_hopsize], rotation=90)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('')\nplt.grid(True)\n\nplt.show()"
  },
  {
    "objectID": "code/data_filtering_activity.html#video",
    "href": "code/data_filtering_activity.html#video",
    "title": "Class Activity",
    "section": "Video",
    "text": "Video\n\n\nCode\n# TODO: watch the video (also linked on the course website) - https://youtu.be/v5pJfu-yn-0\n\n# TODO: What two terms are used instead of logical indexing?"
  },
  {
    "objectID": "code/data_interactivity_activity.html",
    "href": "code/data_interactivity_activity.html",
    "title": "Interactive Data Display Activity",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_interactivity_activity.html#basic-function",
    "href": "code/data_interactivity_activity.html#basic-function",
    "title": "Interactive Data Display Activity",
    "section": "Basic Function",
    "text": "Basic Function\n\n\nCode\nplt.figure(figsize=(8, 4))\nplt.plot([0.1,0.2,0.3,0.4,0.5], [-2,-1,0,1,2], '*-')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Y vs X')\nplt.xlim(0,2)\nplt.ylim(-5,5)\nplt.show()\n\n# TODO: What happens when you run this code cell?\n# TODO: What is the title?\n\n\n\n\nCode\n# Here is a function with the same code as above\n\n\ndef plot_line():\n    plt.figure(figsize=(8, 4))\n    plt.plot([0.1,0.2,0.3,0.4,0.5], [-2,-1,0,1,2], '*-')\n    plt.xlabel('X')\n    plt.ylabel('Y')\n    plt.title('Y vs X')\n    plt.xlim(0,2)\n    plt.ylim(-5,5)\n    plt.show()\n\n\n# TODO: What happens when you run this code cell?\n\n\n\n\nCode\nplot_line()\n\n# TODO: What happens when you run this code cell?\n# TODO: How did the computer know what to do?"
  },
  {
    "objectID": "code/data_interactivity_activity.html#more-interesting-function",
    "href": "code/data_interactivity_activity.html#more-interesting-function",
    "title": "Interactive Data Display Activity",
    "section": "More interesting function",
    "text": "More interesting function\n\n\nCode\n# Create a sine wave with frequency 2 Hz and amplitude 3. Use variable name y\n# Then plot it\n\nfreq = 2\namplitude = 3\n\npi = 3.14159\n\nt = np.arange(0, 2, 2/1000)\ny = amplitude * np.sin(2 * pi * freq * t)\n\n\nplt.figure(figsize=(8, 4))\nplt.plot(t, y, label=f'Sin(2 pi {freq} t) * {amplitude}')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.xlim(0,2)\nplt.ylim(-5,5)\nplt.grid(True)\nplt.show()\n\n# TODO: What happens when you run this code cell?\n\n\n\n\nCode\ndef plot_sine(freq, amplitude):\n\n  pi = 3.14159\n\n  t = np.arange(0, 2, 2/1000)\n  y = amplitude * np.sin(2 * pi * freq * t)\n\n\n  plt.figure(figsize=(8, 4))\n  plt.plot(t, y, label=f'Sin(2 pi {freq} t) * {amplitude}')\n  plt.xlabel('Time (seconds)')\n  plt.ylabel('Amplitude')\n  plt.legend()\n  plt.xlim(0,2)\n  plt.ylim(-5,5)\n  plt.grid(True)\n  plt.show()\n\n# TODO: What happens when you run this code cell?\n# Decribe what you see above that is new\n\n\n\n\nCode\nplt.close('all')\n\nplot_sine(freq=2, amplitude=3)\n\n# TODO: What happens when you run this code cell?\n# TODO: How is it similar or different from above?\n\n\n\n\nCode\nplt.close('all')\n\nplot_sine(freq=2, amplitude=1)\n\n# TODO: What happens when you run this code cell?\n# TODO: How is it similar or different from above?\n\n\n\n\nCode\nplt.close('all')\n\nplot_sine(freq=6, amplitude=1)\n\n# TODO: What happens when you run this code cell?\n# TODO: How is it similar or different from above?"
  },
  {
    "objectID": "code/data_interactivity_activity.html#interactive-function-call",
    "href": "code/data_interactivity_activity.html#interactive-function-call",
    "title": "Interactive Data Display Activity",
    "section": "Interactive function call!",
    "text": "Interactive function call!\n\n\nCode\nplt.close('all')\n\n# The interact function takes the plotting function, and parameters of the plotting function!\n# The parameters of the plotting function turn into sliders\n# the slider must be specified with some information: (start, end, hop)\n\ninteract(plot_sine, freq=(0.1, 10.0, 0.1), amplitude=(0.1, 5.0, 0.1))"
  },
  {
    "objectID": "code/data_interactivity_activity.html#now-with-data-in-a-df",
    "href": "code/data_interactivity_activity.html#now-with-data-in-a-df",
    "title": "Interactive Data Display Activity",
    "section": "Now with Data in a DF",
    "text": "Now with Data in a DF\n\n\nCode\n\n\ndf = pd.read_csv(\n    'https://raw.githubusercontent.com/allegheny-college-cmpsc-105-spring-2025/data-distortion-starter/refs/heads/main/data/data-distortion-noaa-2006-2020-USW00004843.csv',\n    sep=',',\n    names = ['INDEX', 'STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION',\n       'DATE', 'month', 'day', 'hour', 'HLY-TEMP-NORMAL'],\n    skiprows=1\n)\n\nprint(df.head()) # Display the first few rows of the DataFrame\n\n\n\nTODO: In the variable explorer ({x}), what Shape does the variable df have? Write your response here:\n\n\n\nCode\n# a plotting function\n# it has a parameter called month\n\ndef plot_df(month):\n\n    plt.figure(figsize=(8, 4))\n    plt.plot(df.loc[df['month']==month,'INDEX'], df.loc[df['month']==month,'HLY-TEMP-NORMAL'])\n    plt.xticks(df.loc[df['month']==month,'INDEX'][::72], df.loc[df['month']==month,'DATE'][::72], rotation=90)\n    plt.xlabel('Time (hours)')\n    plt.ylabel('Normals (F)')\n    plt.title(f'Month {month}')\n    plt.ylim(-20,100)\n    plt.show()\n\n# TODO: What happens when you run this cell?\n\n\n\n\nCode\nplt.close('all')\n\n\n# The interact function takes the plotting function, and parameters of the plotting function!\n# The parameters of the plotting function turn into sliders\n# the slider must be specified with some information: (start, end, hop)\n\n\ninteract(plot_df, month=(1,12,1))"
  },
  {
    "objectID": "code/data_interactivity_activity.html#you-try",
    "href": "code/data_interactivity_activity.html#you-try",
    "title": "Interactive Data Display Activity",
    "section": "You Try",
    "text": "You Try\n\n\nCode\n# TODOs\n# make a plotting function that has a parameter of month and hour\n# inside the function, set up filtering that considers both the month & hour\n# Make sure the filters select just rows from df that are equal to (==) the selected month and hour\n\n\n\n\nCode\n# TODOs\n# Call your function, but turn the parameters into sliders!\n# the month will only go from 1 to 12\n# the hour should only go from 0 to 24"
  },
  {
    "objectID": "code/data_interactivity_activity.html#discord-post",
    "href": "code/data_interactivity_activity.html#discord-post",
    "title": "Interactive Data Display Activity",
    "section": "Discord Post",
    "text": "Discord Post\nTODO: Post about data that you would like to filter interactively or data that you have seen filtered interactively. These will be shared in class on Thursday."
  },
  {
    "objectID": "code/data_interactivity_activity.html#submit-this-completed-activity-to-your-activities-repository",
    "href": "code/data_interactivity_activity.html#submit-this-completed-activity-to-your-activities-repository",
    "title": "Interactive Data Display Activity",
    "section": "Submit this completed activity to your activities repository",
    "text": "Submit this completed activity to your activities repository"
  },
  {
    "objectID": "syll/syllabus.html",
    "href": "syll/syllabus.html",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "",
    "text": "Class Sessions: TuTh 9:30 AM-10:45 AM, Alden 101\nLaboratory Session: Th, 2:30 PM-4 PM, Alden 101\nInstructor: Professor Emily Graber, egraber@allegheny.edu\nOffice Location: Alden Hall 106\nOffice Hours: Visit Google Calendar to reserve an appointment as needed."
  },
  {
    "objectID": "syll/syllabus.html#course-description",
    "href": "syll/syllabus.html#course-description",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Course Description",
    "text": "Course Description\nAn introduction to the methods of collecting, exploring, transforming and visualizing data for storytelling. Often participating in team-based and hands-on activities, students learn how to use web platforms and dashboards to acquire, explore and investigate data to generate summarized key data insights using visual techniques. Students also apply open-source programming language to discover patterns in the data, test hypotheses, and check assumptions using graphical representations. During a weekly laboratory session, students employ cutting-edge software tools to complete projects, reporting on their results through both written documents and oral presentations. Students are invited to use their own departmentally approved laptop in this course; a limited number of laptops are available for use during class and lab sessions.\nPrerequisite: None\nDistribution Requirements: QR, SP.\nDR tag rationale: This course will primarily focus on methods of data collection, foundational data analysis of numerical data, and visualizations of such data. Additionally, students will participate in the scientific process during the exploratory data analysis and apply scientific reasoning to analyze and synthesize data.\n\nLearning Outcomes\n\nDevelop hypotheses based on motivating problems and/or observations and identify appropriate data to address hypotheses.\nIdentify and describe key elements in different types of data visualizations.\nUse web-based platforms to accurately present data sets through multiple visualizations.\nUse an open-source programming language to compute summary statistics and visualize key patterns in the data.\nContribute to and present structured, web-based documentation that describes data exploration steps and visualization-based conclusions.\n\n\n\nScientific Process and Knowledge (SP)\n\nCourses involving Scientific Process and Knowledge aim to convey an understanding of what is known or can be known about the natural world; apply scientific reasoning towards the analysis and synthesis of scientific information; and create scientifically literate citizens who can engage productively in problem solving.\nLearning Outcome: Students who successfully complete this requirement will demonstrate an understanding of the nature, approaches, and domain of scientific inquiry.\n\n\n\nQuantitative Reasoning (QR)\n\nQuantitative Reasoning is the ability to understand, investigate, communicate, and contextualize numerical, symbolic, and graphical information towards the exploration of natural, physical, behavioral, or social phenomena.\nLearning Outcome: Students who successfully complete this requirement will demonstrate an understanding of how to interpret numeric data and/or their graphical or symbolic representations."
  },
  {
    "objectID": "syll/syllabus.html#schedule-at-a-glance",
    "href": "syll/syllabus.html#schedule-at-a-glance",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Schedule at-a-glance",
    "text": "Schedule at-a-glance\nWelcome\n\nWeek One: January 14, 16: Setup\n\nData Display\n\nWeek Two: January 21, 23: Display Types and Anatomy of a Chart\nWeek Three: January 28, 30: Data Distortion\nWeek Four: February 4, 7: Data Filtering\nWeek Five: February 11, 13: Interactive Display\n\nData Gathering\n\nWeek Six: February 18, 20: Turning Anything Into Data \nWeek Seven: February 25, 27: Web Data Analytics and Scraping\nSpring Break: March 1-9\nWeek Nine: March 11, 13: Data Wrangling\n\nData Processing\n\nWeek Ten: March 18, 20: Statistics Intro\nWeek Eleven: March 25, 27: Inferential Statistics\nWeek Twelve: April 1, 3: Comparing and Modeling\nWeek Thirteen: April 8: Clustering\n\nData Storytelling\n\nWeek Fourteen: April 15, 17: Storytelling Challenge\nWeek Fifteen: April 22, 24: Project Preparation\nWeek Sixteen: April 29: No Class Meeting\n\nFinal Presentations Code C\n\nThursday, May 1st, 2025 at 7:00 PM: Final Project Lightning Talks\n\nComplete Final Exam Schedule"
  },
  {
    "objectID": "syll/syllabus.html#grading",
    "href": "syll/syllabus.html#grading",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Grading",
    "text": "Grading\n\n\n\nAssignment type\nPercentage\n\n\n\n\nLabs\n50%\n\n\nParticipation\n30%\n\n\nFinal Project\n20%\n\n\n\nGrading policy may change as needed during the term; any changes will be announced to the class at the time of the change. Grades will be communicated via Canvas. Please note that attendance policies may additionally affect grades as adjustments to grades will be applied on top of the base grade according to policy\n\nLabs\nThere are 8 labs during the semester. Due dates are hard deadlines. See below for policy on late work.\nThe deliverables for labs include documentation in a GitHub repo addressing specific questions or demonstrating requested calculations, analyses, visualizations, and code snippets.\nLabs will be graded for having clean work with few careless errors, correct Markdown, code, data, correct images given the context of the lab, and correct explanations of concepts in writing\n\n\nParticipation\nParticipation in class work, group activities, and Discord are required. Documentation of in-class participation must be submitted by each student and cannot be made up. Participation on the Discord server can occur throughout each week. Each student is required to post at least once per week by asking either asking a real question or answering a question asked by your classmate. Collegial conversations about course topics or activities are also allowed.\nYou will have access to a repository for submitting all of your class activities. Each activity that you do in class will contribute to your overall participation grade. There is no grading scheme for class activities. I will simply check that the activity was turned in at the end of the class period, and that you have made an effort to do the activity as intended, and figures are showing.\nIf the activity is not turned in at the end of the class period, then it will not be counted toward your participation grade.\n\n\nFinal Project\nThe final project will be open ended. Techniques and skills learned throughout the course should be demonstrated in the project in a final presentation (included in the final project grade). The project must be approved by the teaching team in an initial stage. The artifact can be detailed blog post, following the format of the last lab, or a detailed data visualization with interactive visuals."
  },
  {
    "objectID": "syll/syllabus.html#policies",
    "href": "syll/syllabus.html#policies",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Policies",
    "text": "Policies\n\nAttendance\nStudents are expected to come to class prepared, on time, and to stay engaged for the duration of the class period. This includes both class and lab sessions. This behavior is core to our shared departmental values and is in addition to the college’s attendance policy.\n\nPreparedness\nComing to class prepared means coming with everything you need to engage in a class session. To satisfy basic expectations of CIS courses, this means, at minimum, that students must:\n\narrive at class with a fully charged laptop\nbring their laptop charger or a battery pack so as to ensure that their laptop works throughout the entire class session\ncomplete any pre-session work such as readings and preparatory assignments\n\n\n\nAttendance and Lateness\nOne missed class or lab session counts as one absence. Coming to class/lab late, leaving early, or missing a large portion of a class/lab session will result in your being marked as “late” to class. Coming to class/lab unprepared may also result in being marked “late”. Being marked “late” to class three times during the course of a semester is equal to one absence.\nStudents can have five absences without any impact to their grade. These accommodations are meant to cover illness and emergency, so you should always come to class if you are able to do so.\nAs a general guideline, students cannot miss more than two weeks of class in total throughout the academic semester without receiving a letter grade reduction.\nFor this course, excluding the first week and five excused absences, overall course grade will go down by 1/3 of a letter grade for each additional absence or absence equivalence regardless of base grade.\n\n\nEngagement\nThe term “engagement” or our expectation that students remain “engaged” can mean many things, often varying by course. Baseline behaviors that indicate engagement include:\n\nparticipation in class activities and discussions\ndefined contribution to class sessions in full-class or group discussions\nnote-taking (physical or digital)\nparticipating in course session attendance requirements\nnot participating in non-course related activities\nnot completing non-course related projects\n\n\n\n\nLate Work Policy\nThe deadlines for assignments are hard deadlines. This policy is intended to ensure that students keep up with course topics, are able to actively participate in class, and are accountable for managing time effectively.\nAll students in the CIS department are expected to turn in assignments on time. “On time” means on or before the assignment’s due date. This means that an assignment cannot be turned in for credit after a due date, unless the student applies a token.\n\nTokens\nStudents in 105 are allotted four tokens to receive extensions on any assignment except the final with no questions asked by the course instructor except either in the rare cases of documented severe and/or extenuating circumstances or in cases that violate the CIS policy document or any College-approved policy.\nA token may be applied via a Google Form up to the assignment deadline, with exceptions granted only for severe and/or extenuating circumstances.\nTokens grant an automatic extension of one week to anything except the final exam.\nToken Form for Automatic Extension\n\n\n\nExtenuating Circumstances\nExtenuating circumstances are exceptional, unforeseen, outside of your control, and short-term, like illness and emergency. Regular circumstances associated with taking courses at Allegheny College are not considered extenuating.\nThe accommodations provided by tokens and permitted absences are meant to cover extenuating circumstances like illness, emergency, and work. However, if you have a contagious illness like COVID-19, the flu, or a cold, you should not come to class. If you have expended all your absences and tokens and are still sick with a contagious illness, you may contact your professor about options. If your symptoms are mild or you are recovering from a respiratory illness, we recommend that you wear a mask to class.\nProfessor must be informed of all athletic obligations at the beginning of the semester, or with as much notice as possible. If you are feeling healthy and well, you should make every effort to come to class on time and to complete assignments, rather than using absences and tokens you may need later.\nThese no-questions-asked accommodations are meant to protect student privacy, and to remove the additional effort of acquiring documentation under duress of illness or emergency. In addition, they allow the professor to remain focused on teaching rather than adjudicating excuses.\nIf extenuating circumstances are severe enough to require more absences and tokens, you may contact your professor to discuss options. In most cases, however, a situation of this gravity warrants a request for a “Late Drop” or “Incomplete” in the course, as the student will not have had adequate opportunity to learn the material."
  },
  {
    "objectID": "syll/syllabus.html#resources",
    "href": "syll/syllabus.html#resources",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Resources",
    "text": "Resources\n\nFundamentals of Data Visualization\n\nFull Text\n\nMaking Sense of Data by Glenn J. Myatt and Wayne P. Johnson\n\nI. Exploratory Data Analysis\nII. Data Visualization\nIII. Interactive Visualizations\n\nNaked statistics: stripping the dread from the data by Charles J. Wheelan\n\nGoogle Preview\n\nNatural Resources Biometrics by Diane Kiarnan\n\nFull Text\n\nPython Data Science Handbook by Jake VanderPlas\n\nFull Text\n\nPython for Data Analysis, 3E by Wes McKinney\n\nFull Text\n\nArticles\n\nVariable Types"
  },
  {
    "objectID": "syll/syllabus.html#communications",
    "href": "syll/syllabus.html#communications",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Communications",
    "text": "Communications\n\nUsing GitHub and Discord\nThis course will primarily use GitHub and Discord for collaborative course communication. Communications that are not private matters must take place in the Data Exploration Channel in Discord.\nThe Allegheny College Computer and Information Science Discord Server will also have useful announcements about departmental activities including TL office hours.\n\n\nUsing Email\nAlthough we will primarily use Discord for class communication, the course instructor will sometimes use email to send announcements about important matters such as changes in the schedule. It is your responsibility to check your email at least once a day and to ensure that you can reliably send and receive emails."
  },
  {
    "objectID": "syll/syllabus.html#honor-code",
    "href": "syll/syllabus.html#honor-code",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Honor Code",
    "text": "Honor Code\nThe Academic Honor Program that governs the entire academic program at Allegheny College is described in the Allegheny Academic Bulletin. The Honor Program applies to all work that is submitted for academic credit or to meet non-credit requirements for graduation at Allegheny College. This includes all work assigned for this class (e.g., examinations and course assignments). All students who have enrolled in the College will work under the Honor Program. Each student who has matriculated at the College has acknowledged the following Honor Code pledge:\n\nI hereby recognize and pledge to fulfill my responsibilities, as defined in the Honor Code, and to maintain the integrity of both myself and the College community as a whole.\n\n\nEffective Collaboration\nComputer science is an inherently collaborative discipline. The Department of Computer and Information Science at Allegheny College encourages students to engage in collaboration. However, in the context of individual coursework, through which each student must demonstrate their own knowledge, there are certain forms of collaboration that are and are not acceptable.\n\nAcceptable forms of collaboration include:\n\nDiscussing high-level concepts.\nReferring someone to a course text book, course slides, example programs, or other resources that contain helpful information or instructions.\nOutlining the high-level steps to solving a problem, without mentioning specific\nlines of code that need to be written.\n\nUnacceptable forms of collaboration include:\n\nSharing details about specific lines of code, including showing your source code to someone or looking at someone else’s code.\nCopying someone else’s source code, technical writing, program commands, or program output, even with some slight modifications.\nTyping source code, technical writing, or commands on someone else’s computer.\n\n\n\n\nPlagiarism and Artificial Intelligence\nStudents may not pass off or represent the work of another student, or their own prior work, as their own current work in any case. Plagiarism and AI-generatated code, text, or images are not permitted in any assignment type unless the instructions supplied for the assignment explicitly state otherwise.For exams and all other coursework, students are expected to adhere to the given instructions for the particular exam or item of coursework. It is the responsibility of the student to review the authorization specifications on every item and act appropriately, upholding the honor code. Suspected plagiarized or unauthorized use of AI to generate the work that is turned in will be reported to the Honor Code Committee. This policy does not preclude the use of AI to learn."
  },
  {
    "objectID": "syll/syllabus.html#educational-accommodations",
    "href": "syll/syllabus.html#educational-accommodations",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Educational Accommodations",
    "text": "Educational Accommodations\nThe Americans with Disabilities Act (ADA) is a federal anti-discrimination statute that provides comprehensive civil rights protection for persons with disabilities. Among other things, this legislation requires all students with disabilities be guaranteed a learning environment that provides for reasonable accommodation of their disabilities. Students with disabilities who believe they may need accommodations in this class are encouraged to contact Student Accessibility and Support Services (SASS) at 814-332-2898. Student Accessibility and Support Services is part of the Learning Commons and is located in Pelletier Library. Please do this as soon as possible to ensure that approved accommodations are implemented in a timely fashion."
  },
  {
    "objectID": "syll/syllabus.html#syllabus-changes",
    "href": "syll/syllabus.html#syllabus-changes",
    "title": "Syllabus: CMPSC 105.00 Data Exploration, Spring 2025",
    "section": "Syllabus Changes",
    "text": "Syllabus Changes\nThe instructor may make updates or changes to this document at any time as needed until term grades are due. Changes will be announced to the class."
  },
  {
    "objectID": "code/stats_intro_activity.html",
    "href": "code/stats_intro_activity.html",
    "title": "Statistics",
    "section": "",
    "text": "Open In Colab\n\n\n\nStatistics\n\n\nCode\n# import pd, np, and matplotlib libraries\n\n\n\n\nCode\n# read in temperature normals dataset\n# find raw url from course site repo (https://github.com/allegheny-college-cmpsc-105-spring-2025/site)\n\ndf = pd.read_csv(\n    '',\n    sep=',',\n    skiprows=0\n)\n\n\n\nTODO: In the variable explorer ({x}), what Shape does the variable df have? Write your response here:\n\n\n\nCode\n# TODO: display column names\n\n# TODO: Check the number of rows and columns, i.e. shape\n\n# TODO: Get Rid of uneccessary information\n# df.drop(columns=['Bad_Col1','Bad_Col2', 'etc'])\n\n# TODO: rename individual columns for convenience\n# df = df.rename(columns={'A': 'X', 'B': 'Y', 'C': 'Z'})\n\n# TODO: Check the number of rows and columns, i.e. shape again\n\n\n\n\nCode\n# mean\n# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n# df.mean(axis=1)\n\n\n\n\nCode\n# standard deviation\n# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html\n# df.std()\n\n\n\n\nCode\n# make a figure\n# bar plot of mean\n# errorbars of the standard deviation\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html\n\n\n\n\nCode\n# Calculate the z-scored temperature\n\n\n\n\nCode\n# Make a histogram of the non-z-scored data on one subplot\n# Make a historgram of the z-scored data in another subplot\n\n\n\n\nCode\n# TODO: Answer the following questions\n# - what is the mean and STD of the non-z-scored data\n# - what is the mean and STD of the z-scored data"
  },
  {
    "objectID": "code/data_clustering_activity.html",
    "href": "code/data_clustering_activity.html",
    "title": "Data Clustering Activity",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_clustering_activity.html#discord-post",
    "href": "code/data_clustering_activity.html#discord-post",
    "title": "Data Clustering Activity",
    "section": "Discord Post",
    "text": "Discord Post\nTODO: Don’t forget to ask questions in Discord. One Discord post per week is required."
  },
  {
    "objectID": "code/data_clustering_activity.html#submit-this-completed-activity-to-your-activities-repository",
    "href": "code/data_clustering_activity.html#submit-this-completed-activity-to-your-activities-repository",
    "title": "Data Clustering Activity",
    "section": "Submit this completed activity to your activities repository",
    "text": "Submit this completed activity to your activities repository"
  },
  {
    "objectID": "code/stats_inferential_activity.html",
    "href": "code/stats_inferential_activity.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Open In Colab\n\n\nFor a normal distribution, what is the probability of selecting a z-score that is larger than than \\(z = 1.96\\)?\nTODO: Write python code that can simulate a standard normal distribution and the unit normal table to find the answer\n\n\nCode\nimport scipy\n\n# TODO: import pd, np, and matplotlib libraries\n\n\n\n\nCode\n# TODO: write down the mean of a standard normal distribution\n# TODO: write down the std of a standard normal distribution\n\n# TODO: use a function out of numpy called random.normal, passing in the mean, std, and how many samples to draw\n# https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n\n# TODO: convert to dataframe\n\n\n\n\nCode\n# TODO: sanity check the mean\n# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n# df.mean(axis=1)\n\n\n\n\nCode\n# TODO: sanity check the standard deviation\n# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html\n# df.std()\n\n\n\n\nCode\n# TODO: use scipy stats library to call a function called percentileofscore\n# this function operates on data frames\n# it finds the quantile of the specified z-value with tow parameters, the df and z-value\n\n\n\n\nCode\n# TODO: Sanity check by re-computing the z for a given proportion\n# Use the numpy quantile function to pass in a particular quantile (or area) for\n# which we would like to know the z score boundary\n# https://numpy.org/doc/stable/reference/generated/numpy.quantile.html\n# parameters are the data and the quantile\n\n# TODO: what is the difference between quantile and percentile?\n\n\n\n\nCode\n# TODO: redefine the quantile in terms of an alpha/2\n\n\n\n\nCode\n# TODO: plot the random normal data!\n# NOTE: the density parameter will normalize the y axis\n\n\n# TODO: add a vertical line on your figure to mark the critical z-value\n\n\nWork through this problem and verify everything in code. (Gravetter & Wallnau, Example 7.3)\n\nOnce again, the distribution of SAT scores forms a normal distribution with a mean of \\(\\mu = 500\\) and SEM = 20. For this example, we are going to determine what kind of sample mean is likely to be obtained as the average SAT score for a random sample of N = 25 students (\\(\\sigma = 100\\)). Specifically, we determine the exact range of values that is expected for the sample mean 80% of the time. Our goal is to find the range of values that make up the middle 80% of the distribution. Because the distribution is normal, we can use the unit normal table. First, the 80% in the middle is split in half, with 40% (0.4000) on each side of the mean. Looking up 0.4000 in column D (the proportion between the mean and z), we find a corresponding z-score of z = 1.28. Thus, the z-score boundaries for the middle 80% are z = \\(\\pm 1.28\\). By definition, a z-score of 1.28 represents a location that is 1.28 standard deviations (or standard errors) from the mean. With a standard error of 20 points, the distance from the mean is 1.28 * (20) = 25.6 points. The mean is \\(\\mu = 500\\), so a distance of 25.6 in both directions produces a range of values from 474.4 to 525.6. Thus, 80% of all the possible sample means are contained in a range between 474.4 and 525.6. If we select a sample of N = 25 students, we can be 80% confident that the mean SAT score for the sample will be in this range."
  },
  {
    "objectID": "code/data_wrangling_activity.html",
    "href": "code/data_wrangling_activity.html",
    "title": "Data Wrangling Activity",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_wrangling_activity.html#discord-post",
    "href": "code/data_wrangling_activity.html#discord-post",
    "title": "Data Wrangling Activity",
    "section": "Discord Post",
    "text": "Discord Post\nTODO: Don’t forget to ask questions in Discord. One Discord post per week is required."
  },
  {
    "objectID": "code/data_wrangling_activity.html#submit-this-completed-activity-to-your-activities-repository",
    "href": "code/data_wrangling_activity.html#submit-this-completed-activity-to-your-activities-repository",
    "title": "Data Wrangling Activity",
    "section": "Submit this completed activity to your activities repository",
    "text": "Submit this completed activity to your activities repository"
  },
  {
    "objectID": "code/data_analysis_activity.html",
    "href": "code/data_analysis_activity.html",
    "title": "Data Exploration",
    "section": "",
    "text": "Open In Colab"
  },
  {
    "objectID": "code/data_analysis_activity.html#analyses-of-one-continuous-variable",
    "href": "code/data_analysis_activity.html#analyses-of-one-continuous-variable",
    "title": "Data Exploration",
    "section": "Analyses of one continuous variable",
    "text": "Analyses of one continuous variable\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nimport pandas as pd\n\n\n\n\nCode\ndata = {\n    'y': [1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10],\n    'category' : ['control', 'control', 'control', 'control', 'control', 'test', 'test', 'test', 'test', 'test'],\n}\n\ndf = pd.DataFrame(data)\n\n\n\nTODO: In the variable explorer ({x}), what Shape does the variable df have? Write your response here:\n\n\n\nCode\ndf\n\n\n\n\nCode\ny_bar = df['y'].mean() # sample mean\nSEM = df['y'].std() / (len(df) ** 0.5) # standard error of the mean\nscore = ( y_bar - 0 ) / SEM\nz_crit  = 1.96 # for 95% boundary with two tails, recall z = 1.96\n\nprint(score)\nprint('probablity of this score is...?')\n\n\n\n\nCode\nscore, probability = scipy.stats.ttest_1samp(df['y'], 0)\n\nprint(score)\nprint(probability)\n\n\n\n\nCode\n# Examine the Data\n\nplt.figure()\nplt.plot(df['y'])\nplt.ylabel('y')\nplt.xlabel('observation number (arbitrary)')\nplt.show()\n\n\n\n\nCode\n# split the data, i.e. filter\n\nplt.figure()\nplt.plot(df['y'][df['category'] =='control'])\nplt.plot(df['y'][df['category'] =='test'])\nplt.legend({'test', 'control'})\nplt.ylabel('y')\nplt.xlabel('observation number (arbitrary)')\nplt.show()\n\n\n\n\nCode\n# Find the average value per category\n\nplt.figure()\nplt.bar([1,2], [df['y'][df['category'] =='control'].mean(), df['y'][df['category'] =='test'].mean()])\nplt.ylabel('y')\nplt.xticks([1,2], ['control', 'mean'])\nplt.title('Average y per Category')\nplt.show()\n\n\n\n\nCode\n# Test the means\n\nscore, probability = scipy.stats.ttest_ind(\n    df['y'][df['category'] =='control'],\n    df['y'][df['category'] =='test'])\n\nprint(score)\nprint(probability)"
  },
  {
    "objectID": "code/data_analysis_activity.html#analyses-of-two-continuous-variables",
    "href": "code/data_analysis_activity.html#analyses-of-two-continuous-variables",
    "title": "Data Exploration",
    "section": "Analyses of two continuous variables",
    "text": "Analyses of two continuous variables\n\n\nCode\ndf['x'] = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf\n\n\n\n\nCode\nplt.figure()\nplt.scatter(df['x'],df['y'])\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()\n\n\n\n\nCode\n# Compute pearson correlation\n\nnumerator = np.sum((df.x - df.x.mean()) * (df.y - df.y.mean()))\ndenominator = (sum( (df.x - df.x.mean())**2 ) * sum( (df.y - df.y.mean())**2 )) ** 0.5\n\nr = numerator / denominator\nprint(r)\n\n\n\n\nCode\nscore, probability = scipy.stats.pearsonr(df.x, df.y)\n\nprint(score)\nprint(probability)"
  },
  {
    "objectID": "code/data_analysis_activity.html#questions",
    "href": "code/data_analysis_activity.html#questions",
    "title": "Data Exploration",
    "section": "Questions",
    "text": "Questions\n\n\nCode\n# TODO: what library contains pre-coded tests?\n# TODO: why is filtering important for analysis?\n# TODO: explore the code to confirm"
  },
  {
    "objectID": "grades.html",
    "href": "grades.html",
    "title": "Grades",
    "section": "",
    "text": "Please check Canvas for your grades here"
  },
  {
    "objectID": "slides/07-web-data.html#goals",
    "href": "slides/07-web-data.html#goals",
    "title": "Week 7: Web Data",
    "section": "Goals",
    "text": "Goals\n\nWebsite structure\nGathering content off the web\nGathering data about web usage\n\nGoogle Analytics"
  },
  {
    "objectID": "slides/07-web-data.html#raw-file-types",
    "href": "slides/07-web-data.html#raw-file-types",
    "title": "Week 7: Web Data",
    "section": "Raw File Types",
    "text": "Raw File Types\n\n\nHTML - Hypertext Markup Language\nCSS - Cascading Style Sheets\nXML - Extensible Markup Language\n(also javascript for coding interactions with buttons, and dynamically loading content)"
  },
  {
    "objectID": "slides/07-web-data.html#examples",
    "href": "slides/07-web-data.html#examples",
    "title": "Week 7: Web Data",
    "section": "Examples",
    "text": "Examples\n\n\nHTML\n\nnotice tags &lt;p&gt;&lt;/p&gt;, &lt;div&gt;&lt;/div&gt;\ncontent is inside of tags\nnot WYSIWYG like MS Word documents\n\nCSS\n\nnotice metadata marking things like font names and colors\n\n“font-family:”\n“color:”\n\nhttps://quarto.org/docs/output-formats/html-themes.html\n\nXML\n\nhierarchical (nested structure)\ntagged metadata\n\n(javascript)\n\n\n\nhttps://www.oreilly.com/library/view/xml-in-a/0596007647/ch01s05.html"
  },
  {
    "objectID": "slides/07-web-data.html#metadata",
    "href": "slides/07-web-data.html#metadata",
    "title": "Week 7: Web Data",
    "section": "Metadata",
    "text": "Metadata\n\nApplications like your browser need to know metadata about content.\n\n\nwhat kind of content is it?\nif it is a paragraph, it should be rendered one way\nif it is an image, it should be rendered a different way\nif it is a url, it should be clickable"
  },
  {
    "objectID": "slides/07-web-data.html#example",
    "href": "slides/07-web-data.html#example",
    "title": "Week 7: Web Data",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/07-web-data.html#other-markup",
    "href": "slides/07-web-data.html#other-markup",
    "title": "Week 7: Web Data",
    "section": "Other Markup",
    "text": "Other Markup\n\n\nLaTeX - Compiled Markup, often used for rendering mathematical expressions\nmarkdown\n\n\n\n## Report for Data Exploration\n\n### Introduction\n\nData was explored using different chart types.\n\n### Methods\n\nMatplotlib functions for making line charts, boxplots, and historgrams were used."
  },
  {
    "objectID": "slides/07-web-data.html#rendered-version",
    "href": "slides/07-web-data.html#rendered-version",
    "title": "Week 7: Web Data",
    "section": "Rendered version",
    "text": "Rendered version\n\nReport for Data Exploration\nIntroduction\nData was explored using different chart types.\nMethods\nMatplotlib functions for making line charts, boxplots, and historgrams were used."
  },
  {
    "objectID": "slides/07-web-data.html#summary-of-website-structure",
    "href": "slides/07-web-data.html#summary-of-website-structure",
    "title": "Week 7: Web Data",
    "section": "Summary of Website Structure",
    "text": "Summary of Website Structure\n\n\nwebsites use structured texts that can be rendered\nmetadata tags are everywhere\nmetadata tags describe the data and can be used to locate data"
  },
  {
    "objectID": "slides/07-web-data.html#how-things-end-up-in-search-engine-results",
    "href": "slides/07-web-data.html#how-things-end-up-in-search-engine-results",
    "title": "Week 7: Web Data",
    "section": "How Things End Up in Search Engine Results",
    "text": "How Things End Up in Search Engine Results\nsearch engine bots, aka crawlers or spiders, need to know about all the pages on a website and all the content on the pages in order to make it indexable, i.e. usable for web searching.\nA Google bot has to discover webpages, crawl them, index them, and query a giant database to return related content to search terms."
  },
  {
    "objectID": "slides/07-web-data.html#discovery",
    "href": "slides/07-web-data.html#discovery",
    "title": "Week 7: Web Data",
    "section": "Discovery",
    "text": "Discovery\n\n\ndone with robots.txt\nsitemaps"
  },
  {
    "objectID": "slides/07-web-data.html#robots.txt",
    "href": "slides/07-web-data.html#robots.txt",
    "title": "Week 7: Web Data",
    "section": "robots.txt",
    "text": "robots.txt"
  },
  {
    "objectID": "slides/07-web-data.html#robots.txt-1",
    "href": "slides/07-web-data.html#robots.txt-1",
    "title": "Week 7: Web Data",
    "section": "robots.txt",
    "text": "robots.txt\n\n\ndirectives tell bots where to go / not go (“disallow”)\n\nhelps protect information (in theory) on admin pages or other private pages\nhelps keep search engine results relevant\ncould prevent duplication if duplicate information is on a website\n\nincludes links to sitemaps!"
  },
  {
    "objectID": "slides/07-web-data.html#sitemaps",
    "href": "slides/07-web-data.html#sitemaps",
    "title": "Week 7: Web Data",
    "section": "Sitemaps",
    "text": "Sitemaps\n\n\nlists out all pages (unique urls) of a website that should be indexed\nthese can be used to scrape information off a website\nlarge websites may have multiple site maps"
  },
  {
    "objectID": "slides/07-web-data.html#sitemaps-1",
    "href": "slides/07-web-data.html#sitemaps-1",
    "title": "Week 7: Web Data",
    "section": "Sitemaps",
    "text": "Sitemaps\n\n\nhttps://markitors.com/what-is-a-sitemap/"
  },
  {
    "objectID": "slides/07-web-data.html#participation",
    "href": "slides/07-web-data.html#participation",
    "title": "Week 7: Web Data",
    "section": "Participation",
    "text": "Participation\n\nhow many sitemaps does Facebook have?\nhow many sitemaps does Allegheny have?\nWalmart?\nOn another sharable site, see what you find and post a sitemap in Discord!"
  },
  {
    "objectID": "slides/07-web-data.html#crawling",
    "href": "slides/07-web-data.html#crawling",
    "title": "Week 7: Web Data",
    "section": "Crawling",
    "text": "Crawling"
  },
  {
    "objectID": "slides/07-web-data.html#indexing",
    "href": "slides/07-web-data.html#indexing",
    "title": "Week 7: Web Data",
    "section": "Indexing",
    "text": "Indexing"
  },
  {
    "objectID": "slides/07-web-data.html#scraping",
    "href": "slides/07-web-data.html#scraping",
    "title": "Week 7: Web Data",
    "section": "Scraping",
    "text": "Scraping\n\nregular people (not Google) can also get content off the web by using strategies similar to discorvery, crawling, and indexing."
  },
  {
    "objectID": "slides/07-web-data.html#scrapping-tools",
    "href": "slides/07-web-data.html#scrapping-tools",
    "title": "Week 7: Web Data",
    "section": "Scrapping tools",
    "text": "Scrapping tools\n\nCode: Requests, BeautifulSoup\nApplications:\n\n\n    \n\nCredit: Octoparse"
  },
  {
    "objectID": "slides/07-web-data.html#data-miner",
    "href": "slides/07-web-data.html#data-miner",
    "title": "Week 7: Web Data",
    "section": "Data Miner",
    "text": "Data Miner"
  },
  {
    "objectID": "slides/07-web-data.html#optional-activity",
    "href": "slides/07-web-data.html#optional-activity",
    "title": "Week 7: Web Data",
    "section": "Optional Activity",
    "text": "Optional Activity\n\nTry to get a csv file from dataminer\n\nclick on make your own recipe\n\n\nname it data-scraping-activity.csv\nupload to your activities repo"
  },
  {
    "objectID": "slides/07-web-data.html#summary-of-gathering-content-off-the-web",
    "href": "slides/07-web-data.html#summary-of-gathering-content-off-the-web",
    "title": "Week 7: Web Data",
    "section": "Summary of gathering content off the web",
    "text": "Summary of gathering content off the web\n\nthanks to structured text on the web, scraping code or programs can gather information and turn it into useable data for exploration."
  },
  {
    "objectID": "slides/07-web-data.html#google-analytics",
    "href": "slides/07-web-data.html#google-analytics",
    "title": "Week 7: Web Data",
    "section": "Google Analytics",
    "text": "Google Analytics\nsee Data Analytics Slides"
  },
  {
    "objectID": "slides/07-web-data.html#end",
    "href": "slides/07-web-data.html#end",
    "title": "Week 7: Web Data",
    "section": "End",
    "text": "End"
  },
  {
    "objectID": "slides/01-welcome.html#cmpsc-105---data-exploration",
    "href": "slides/01-welcome.html#cmpsc-105---data-exploration",
    "title": "Welcome to CMPSC 105",
    "section": "CMPSC 105 - Data Exploration",
    "text": "CMPSC 105 - Data Exploration\n\nSpring 2025\n\nTu/Th 9:30-10:45am\n\nTh 2:30-4pm\n\nAlden 101"
  },
  {
    "objectID": "slides/01-welcome.html#where-are-we",
    "href": "slides/01-welcome.html#where-are-we",
    "title": "Welcome to CMPSC 105",
    "section": "Where are we?",
    "text": "Where are we?\n\n\nDepartment of Computer and Information Science\nFour Majors/Minors\n\nComputer Science\nData Science\nInformatics\nSoftware Engineering\n\nCommon Doubles\n\nArt, Science, and Innovation\nEconomics"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-this-course-about",
    "href": "slides/01-welcome.html#what-is-this-course-about",
    "title": "Welcome to CMPSC 105",
    "section": "What is this course about?",
    "text": "What is this course about?\n\n\nthis course is for anyone interested in becoming familiar with:\n\ndata visualization\ndata analysis\ndata gathering\ndata storytelling\n\njump starts independent research projects with generalizable skills\nCIS Informatics Major\nCIS Data Science Major/Minor"
  },
  {
    "objectID": "slides/01-welcome.html#learning-outcomes",
    "href": "slides/01-welcome.html#learning-outcomes",
    "title": "Welcome to CMPSC 105",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nIdentify and describe key elements in different types of data visualizations.\nVisualize data on web-based platforms.\nDevelop hypotheses and find data to address hypotheses.\nCalculate statistics and visualize key patterns in the data with Python.\nDocument data explorations in markdown."
  },
  {
    "objectID": "slides/01-welcome.html#other-syllabus-highlights",
    "href": "slides/01-welcome.html#other-syllabus-highlights",
    "title": "Welcome to CMPSC 105",
    "section": "Other Syllabus Highlights",
    "text": "Other Syllabus Highlights\n\n\nParticipation is a major part of participation (30% of overall grade)\n\nDiscord use at least once per week\nCompleting group work\nQuizzes on readings and other class materials\n\nLabs are due before lab, but four tokens grant automatic extensions for one week\nAfter the first week, five absences will be excused before overall grade is impacted\n\nthree lates are equivalent to an absence"
  },
  {
    "objectID": "slides/01-welcome.html#materials",
    "href": "slides/01-welcome.html#materials",
    "title": "Welcome to CMPSC 105",
    "section": "Materials",
    "text": "Materials\n\n\nCourse Website\n\nsyllabus\nassignment schedule for reading and lab due dates\ncourse materials"
  },
  {
    "objectID": "slides/01-welcome.html#materials-continued",
    "href": "slides/01-welcome.html#materials-continued",
    "title": "Welcome to CMPSC 105",
    "section": "Materials Continued",
    "text": "Materials Continued\n\n\nGitHub for accessing and submitting assignments\nGoogle Colab for completing assignments\nGoogle Forms\nDiscord for announcements and participation\nCanvas for grades"
  },
  {
    "objectID": "slides/01-welcome.html#tell-us-about-yourself",
    "href": "slides/01-welcome.html#tell-us-about-yourself",
    "title": "Welcome to CMPSC 105",
    "section": "Tell us about yourself!",
    "text": "Tell us about yourself!\n\nName, where you are from, first favorite band, and some of your current favorite foods?"
  },
  {
    "objectID": "slides/01-welcome.html#cis-shared-values",
    "href": "slides/01-welcome.html#cis-shared-values",
    "title": "Welcome to CMPSC 105",
    "section": "CIS Shared Values",
    "text": "CIS Shared Values"
  },
  {
    "objectID": "slides/01-welcome.html#partnerships",
    "href": "slides/01-welcome.html#partnerships",
    "title": "Welcome to CMPSC 105",
    "section": "Partnerships",
    "text": "Partnerships\n\nStudents who have experience with GitHub, Python, Python Notebooks, Discord\nStudents new to computer science"
  },
  {
    "objectID": "slides/01-welcome.html#setting-up",
    "href": "slides/01-welcome.html#setting-up",
    "title": "Welcome to CMPSC 105",
    "section": "Setting up",
    "text": "Setting up\n\nbookmark the website\nbookmark access to your repos\nbookmark the 105 Discord Channel, or access from the course website\nbookmark notes that you take in Google Colab or elsewhere\nbookmark Canvas\netc."
  },
  {
    "objectID": "slides/12-correlation.html#goals",
    "href": "slides/12-correlation.html#goals",
    "title": "Week 12: Testing For Relationships",
    "section": "Goals",
    "text": "Goals\n\nAnalyses for one continuous variable\nAnalyses for two continuous variables\nActivity on Data Analysis"
  },
  {
    "objectID": "slides/12-correlation.html#find-sample-mean",
    "href": "slides/12-correlation.html#find-sample-mean",
    "title": "Week 12: Testing For Relationships",
    "section": "Find sample mean",
    "text": "Find sample mean\n\nconsider a continuous variable\nfinding the mean and std are the most basic forms of analysis"
  },
  {
    "objectID": "slides/12-correlation.html#hypothesis-test-if-the-sample-mean-is-not-likely-0",
    "href": "slides/12-correlation.html#hypothesis-test-if-the-sample-mean-is-not-likely-0",
    "title": "Week 12: Testing For Relationships",
    "section": "Hypothesis test if the sample mean is not likely 0",
    "text": "Hypothesis test if the sample mean is not likely 0\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\ny_bar = np.mean(y) # sample mean\nSEM = np.std(y, ddof=1) / (len(y) ** 0.5) # standard error of the mean\nscore = ( y_bar - 0 ) / SEM\nz_crit  = 1.96 # for 95% boundary with two tails, recall z = 1.96\n\nprint(score)\nprint('probablity of this score is...?')\n\n5.957419483045198\nprobablity of this score is...?"
  },
  {
    "objectID": "slides/12-correlation.html#alternative-using-code",
    "href": "slides/12-correlation.html#alternative-using-code",
    "title": "Week 12: Testing For Relationships",
    "section": "Alternative using code",
    "text": "Alternative using code\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\n\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\nscore, probability = scipy.stats.ttest_1samp(y, 0)\n\nprint(score)\nprint(probability)"
  },
  {
    "objectID": "slides/12-correlation.html#examine-the-data",
    "href": "slides/12-correlation.html#examine-the-data",
    "title": "Week 12: Testing For Relationships",
    "section": "Examine the data",
    "text": "Examine the data\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncategory = np.array(['control', 'control', 'control', 'control', 'control', 'test', 'test', 'test', 'test', 'test'])\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\n\n\nplt.figure()\nplt.plot(y)\nplt.ylabel('y')\nplt.xlabel('observation number (arbitrary)')\nplt.show()"
  },
  {
    "objectID": "slides/12-correlation.html#breaking-up-a-variable-into-categories",
    "href": "slides/12-correlation.html#breaking-up-a-variable-into-categories",
    "title": "Week 12: Testing For Relationships",
    "section": "Breaking up a variable into categories",
    "text": "Breaking up a variable into categories\n\nwhat if I split y into control and test\nthen the mean in each category could be compared\n\n\n\nplt.figure()\nplt.plot(y[category=='control'])\nplt.plot(y[category=='test'])\nplt.legend({'test', 'control'})\nplt.ylabel('y')\nplt.xlabel('observation number (arbitrary)')\nplt.show()"
  },
  {
    "objectID": "slides/12-correlation.html#breaking-up-a-variable-into-categories-1",
    "href": "slides/12-correlation.html#breaking-up-a-variable-into-categories-1",
    "title": "Week 12: Testing For Relationships",
    "section": "Breaking up a variable into categories",
    "text": "Breaking up a variable into categories\n\nwhat if I split y into control and test\nthen the sample mean in each category could be compared\n\n\nplt.figure()\nplt.bar([1,2], [np.mean(y[category=='control']), np.mean(y[category=='test'])])\nplt.ylabel('y')\nplt.xticks([1,2], ['control', 'mean'])\nplt.show()"
  },
  {
    "objectID": "slides/12-correlation.html#are-these-means-actually-different",
    "href": "slides/12-correlation.html#are-these-means-actually-different",
    "title": "Week 12: Testing For Relationships",
    "section": "Are these means actually different?",
    "text": "Are these means actually different?\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\n\ncategory = np.array(['control', 'control', 'control', 'control', 'control', 'test', 'test', 'test', 'test', 'test'])\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\nscore, probability = scipy.stats.ttest_ind(y[category=='control'], y[category=='test'])\n\nprint(score)\nprint(probability)"
  },
  {
    "objectID": "slides/12-correlation.html#scatterplots",
    "href": "slides/12-correlation.html#scatterplots",
    "title": "Week 12: Testing For Relationships",
    "section": "Scatterplots",
    "text": "Scatterplots\n\nshow relationships between two variables\nthe x axis is for first variable\nthe y axis is for second variable\neach dot is one observation"
  },
  {
    "objectID": "slides/12-correlation.html#scatterplot-example",
    "href": "slides/12-correlation.html#scatterplot-example",
    "title": "Week 12: Testing For Relationships",
    "section": "Scatterplot Example",
    "text": "Scatterplot Example\n\n\nOnce every two weeks for a year, we have recorded the number of air conditions sold and the number of ice cream cones sold on that day.\nHow many observations would that be?\nWhat do you think the relationship would look like?"
  },
  {
    "objectID": "slides/12-correlation.html#scatterplot-example-1",
    "href": "slides/12-correlation.html#scatterplot-example-1",
    "title": "Week 12: Testing For Relationships",
    "section": "Scatterplot Example",
    "text": "Scatterplot Example\n\n\n\nwhat is on x?\nwhat is on y?\nif you see a clear upward or downward slope, that means that the variables are related\nn.b. a relationship does not imply causation!"
  },
  {
    "objectID": "slides/12-correlation.html#scatterplot-example-2",
    "href": "slides/12-correlation.html#scatterplot-example-2",
    "title": "Week 12: Testing For Relationships",
    "section": "Scatterplot Example",
    "text": "Scatterplot Example\nFind a positive relationship, negative relationship, no relationship, a non-linear relationship"
  },
  {
    "objectID": "slides/12-correlation.html#correlation",
    "href": "slides/12-correlation.html#correlation",
    "title": "Week 12: Testing For Relationships",
    "section": "Correlation",
    "text": "Correlation\n\nPearson Correction, \\(r\\) is defined:\n\n\\[\nr = {\\Sigma_{i = 1}^N (x_i - \\bar x)(y_i - \\bar y) \\over \\sqrt {\\Sigma_{i = 1}^N (x_i - \\bar x)^2 \\times \\Sigma_{i = 1}^N(y_i - \\bar y)^2}}\n\\]\n\ncorrelation of 1 is perfect positive slope\ncorrelation of -1 is perfect negative slope\ncorrelation of 0 is 0 or no slope"
  },
  {
    "objectID": "slides/12-correlation.html#correlation-example",
    "href": "slides/12-correlation.html#correlation-example",
    "title": "Week 12: Testing For Relationships",
    "section": "Correlation Example",
    "text": "Correlation Example\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\nplt.figure()\nplt.scatter(x,y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()"
  },
  {
    "objectID": "slides/12-correlation.html#correlation-example-1",
    "href": "slides/12-correlation.html#correlation-example-1",
    "title": "Week 12: Testing For Relationships",
    "section": "Correlation Example",
    "text": "Correlation Example\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\nnumerator = np.sum((x - np.mean(x)) * (y - np.mean(y)))\ndenominator = (sum( (x - np.mean(x))**2 ) * sum( (y - np.mean(y))**2 )) ** 0.5\n\nr = numerator / denominator\nprint(r)\n\n0.979131432462635"
  },
  {
    "objectID": "slides/12-correlation.html#correlation-example-in-practice",
    "href": "slides/12-correlation.html#correlation-example-in-practice",
    "title": "Week 12: Testing For Relationships",
    "section": "Correlation Example in practice",
    "text": "Correlation Example in practice\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\n\nx = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ny = np.array([1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 6, 7.1, 9.9, 10])\n\nscore, probability = scipy.stats.pearsonr(x, y)\n\nprint(score)\nprint(probability)"
  },
  {
    "objectID": "slides/12-correlation.html#activity",
    "href": "slides/12-correlation.html#activity",
    "title": "Week 12: Testing For Relationships",
    "section": "Activity",
    "text": "Activity\ndata_analysis_activity.ipynb"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#goals",
    "href": "slides/11-inferential-statistics.html#goals",
    "title": "Week 11: Inferential Statistics",
    "section": "Goals",
    "text": "Goals\n\nStandard Normal Distribution\nSingle-sample vs multi-sample statistics\nActivity"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#standard-normal-distribution-1",
    "href": "slides/11-inferential-statistics.html#standard-normal-distribution-1",
    "title": "Week 11: Inferential Statistics",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\ny axis is proportion\nx axis is z-scores, i.e. how many standard deviations away something is from the mean\nrecall \\(z_i = {x_i - \\bar x \\over \\sigma}\\)\narea under the curve is unity, 1 aka 100%"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#proportions-vs-z-scores",
    "href": "slides/11-inferential-statistics.html#proportions-vs-z-scores",
    "title": "Week 11: Inferential Statistics",
    "section": "Proportions vs Z scores",
    "text": "Proportions vs Z scores\n\n\n\nz-scores are on the x axis\nproportions above and below a certain z-score are the area under the curve\nwhat z-score boundary would separate 2.2% of the area in the right tail?\n2"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#proportions-vs-z-scores-1",
    "href": "slides/11-inferential-statistics.html#proportions-vs-z-scores-1",
    "title": "Week 11: Inferential Statistics",
    "section": "Proportions vs Z scores",
    "text": "Proportions vs Z scores\n\n\n\nz-scores are on the x axis\nproportions above and below a certain z-score are the area under the curve\nwhat z-score boundary would separate 15.8% of the area in the left tail?\n-1"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#proportions-vs-z-scores-2",
    "href": "slides/11-inferential-statistics.html#proportions-vs-z-scores-2",
    "title": "Week 11: Inferential Statistics",
    "section": "Proportions vs Z scores",
    "text": "Proportions vs Z scores\n\n\n\nwhat \\(\\pm\\) z-score boundary would separate 4.4% of the area split between the right and left tails?\n\\(\\pm\\) 2\nFancy way to ask the same thing: \\(\\alpha\\) is .044, \\(\\alpha/2\\) is 0.022, what is \\(z_{\\alpha/2}\\)?"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#what-is-alpha",
    "href": "slides/11-inferential-statistics.html#what-is-alpha",
    "title": "Week 11: Inferential Statistics",
    "section": "What is \\(\\alpha\\)?",
    "text": "What is \\(\\alpha\\)?\n\n\n\n\\(\\alpha\\) is the greek letter used to talk about proportions of the data out of a total of 1.\n\\(\\alpha/2\\) is simple division, splitting the area in half\n\\(z_{\\alpha/2}\\) is asking for a z-score off the x-axis that sections off the requested area.\nif \\(\\alpha\\) is .05, what is \\(z_{\\alpha/2}\\)?\nslightly less than 2"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#all-z-values---unit-normal-table",
    "href": "slides/11-inferential-statistics.html#all-z-values---unit-normal-table",
    "title": "Week 11: Inferential Statistics",
    "section": "All Z Values - Unit Normal Table",
    "text": "All Z Values - Unit Normal Table\n\nFull Unit Normal Table"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#question-1",
    "href": "slides/11-inferential-statistics.html#question-1",
    "title": "Week 11: Inferential Statistics",
    "section": "Question 1",
    "text": "Question 1\nFor a normal distribution, what is the probability of selecting a z-score that is larger than than \\(z = 1.96\\)?\n\nUnit Normal Table for standard normal distribution"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#z-scores-and-inferential-statistics",
    "href": "slides/11-inferential-statistics.html#z-scores-and-inferential-statistics",
    "title": "Week 11: Inferential Statistics",
    "section": "Z scores and Inferential Statistics",
    "text": "Z scores and Inferential Statistics\nZ scores and the standard normal distribution are essential for inferential statistics.\n\n\nz scores make all data comparable\nthe standard normal distribution has a fixed area of 1 and can be understood in terms of probability\nwe can now ask formalized questions\nwhat z-score must some data have for it to only occur 5% of the time or less?\nn.b. 5% is a nice threshold which is commonly accepted as being statistically meaningful"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#sample-vs-population",
    "href": "slides/11-inferential-statistics.html#sample-vs-population",
    "title": "Week 11: Inferential Statistics",
    "section": "Sample vs Population",
    "text": "Sample vs Population\n\nA sample of the human population might be everyone in this classroom, Alden 101. Another sample might be everyone in Alden 109. Another sample might be everyone in Brooks."
  },
  {
    "objectID": "slides/11-inferential-statistics.html#observations",
    "href": "slides/11-inferential-statistics.html#observations",
    "title": "Week 11: Inferential Statistics",
    "section": "Observations",
    "text": "Observations\n\nFor each sample, there are multiple observations.\nIf I ask everyone in Alden 101 their birth weight, how many observations will there be in the sample?"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#sample-statistics",
    "href": "slides/11-inferential-statistics.html#sample-statistics",
    "title": "Week 11: Inferential Statistics",
    "section": "Sample Statistics",
    "text": "Sample Statistics\n\n\nStatistics like mean, median, mode, std are descriptive summaries of a sample of a population.\nStatistics that come from a single sample are called a sample mean, sample std. But…\nThe sample mean of birth weight in Alden 101 is likely slightly different than the sample mean of birth weight in Alden 109 right now!\nThis means that there exists a distribution of sample means for birth weight!\nThe hypothetical distribution of sample means is called the sampling distribution."
  },
  {
    "objectID": "slides/11-inferential-statistics.html#sampling-distribution",
    "href": "slides/11-inferential-statistics.html#sampling-distribution",
    "title": "Week 11: Inferential Statistics",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#sampling-distribution-statistics",
    "href": "slides/11-inferential-statistics.html#sampling-distribution-statistics",
    "title": "Week 11: Inferential Statistics",
    "section": "Sampling Distribution Statistics",
    "text": "Sampling Distribution Statistics\n\n\nthe sampling distribution is conceptually from multiple samples, and has stats.\nthe mean of the sampling distribution is the expected value of the mean\nthe std of the sampling distribution is the standard error of the mean, \\(SEM\\)\nnote that we can’t actually measure multiple samples, we never see the sampling distribution\nmathematically and statistically, we can use it\nThe central limit theorem states:\n\nFor any population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), the distribution of sample means for sample size N will have a mean of \\(\\mu\\) and a standard deviation of \\(SEM = {\\sigma \\over \\sqrt{N}}\\) and will approach a normal distribution as n approaches infinity, but N = 30 is close enough."
  },
  {
    "objectID": "slides/11-inferential-statistics.html#sampling-distribution-shape",
    "href": "slides/11-inferential-statistics.html#sampling-distribution-shape",
    "title": "Week 11: Inferential Statistics",
    "section": "Sampling Distribution Shape",
    "text": "Sampling Distribution Shape\nNote how the sampling distribution narrows as more observations (N) are used to make the sampling distribution"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#class-coin-exercise",
    "href": "slides/11-inferential-statistics.html#class-coin-exercise",
    "title": "Week 11: Inferential Statistics",
    "section": "Class Coin Exercise",
    "text": "Class Coin Exercise\n\nmake a sample with three coin flips (heads = 0, tails = 1). Compute the sample mean with N=3\nmake a sample with ten coin flips (heads = 0, tails = 1). Compute the sample mean with N=10"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#standard-error-of-the-mean",
    "href": "slides/11-inferential-statistics.html#standard-error-of-the-mean",
    "title": "Week 11: Inferential Statistics",
    "section": "Standard Error of the Mean",
    "text": "Standard Error of the Mean\n\\[\nSEM = {\\sigma \\over \\sqrt{N}}\n\\]\n\n\nrecall, SEM is the standard deviation of the sampling distribution\nSEM can be calculated from ONE SAMPLE\nIt is desirable to have a small SEM because that would signify that the all the data are close to the true population mean!\nif N of the single sample is very large, the SEM will be small\nif \\(\\sigma\\) of a single sample is small, the SEM will be small"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#z-scores-for-one-sample-in-a-sampling-distribution",
    "href": "slides/11-inferential-statistics.html#z-scores-for-one-sample-in-a-sampling-distribution",
    "title": "Week 11: Inferential Statistics",
    "section": "Z scores for one Sample in a Sampling Distribution",
    "text": "Z scores for one Sample in a Sampling Distribution\n\n\nassume the sampling distribution has mean \\(\\mu\\) and standard deviation \\(SEM = {\\sigma \\over \\sqrt{N}}\\)\nassume the single sample mean \\(\\bar x\\)\nrecall that z-scored observations from single sample relate each sample to the sample mean \\(z_i = {x_i - \\bar x \\over \\sigma}\\)\n\\(z_{sample} = {\\mu - \\bar x \\over SEM}\\)"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#question-2",
    "href": "slides/11-inferential-statistics.html#question-2",
    "title": "Week 11: Inferential Statistics",
    "section": "Question 2",
    "text": "Question 2\nThe population distribution of SAT scores is normal with a mean of \\(\\mu = 500\\). For a random sample of 25 students (N = 25) and a standard deviation of \\(\\sigma = 100\\), what is the probability that the sample mean \\(\\bar x\\) will be greater than 540? Greater than 700?\n\nUnit Normal Table for standard normal distribution\n\n\nfor \\(\\bar x = 540\\), \\(p = 0.0228\\), so it is quite unlikely for a sample of 25 students to get an average SAT score higher than 540."
  },
  {
    "objectID": "slides/11-inferential-statistics.html#making-confident-statements",
    "href": "slides/11-inferential-statistics.html#making-confident-statements",
    "title": "Week 11: Inferential Statistics",
    "section": "Making Confident Statements",
    "text": "Making Confident Statements\n\nWe can say with a set level of confidence that a single sample mean is within a certain interval, using the following formula:\n\n\\[\n\\bar x \\pm z_{\\alpha/2} \\times SEM \\\\\nSEM = {\\sigma \\over \\sqrt{N}}\n\\]\n\n\\(z_{\\alpha/2}\\) is a fixed number read off of a standard normal distribution when \\(\\alpha\\) is chosen.\n\\(\\alpha\\) represents the chance that we are wrong, and is area under the curve. It is a proportion of 1, usually, 0.05."
  },
  {
    "objectID": "slides/11-inferential-statistics.html#confidence-intervals",
    "href": "slides/11-inferential-statistics.html#confidence-intervals",
    "title": "Week 11: Inferential Statistics",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nCIs are chosen by researchers, 95% confidence level is common choice.\n95% refers to area under a Standard Normal Distribution and corresponds with \\(\\alpha\\) of .05\nThe Interval that is reported is the z-score that sections off the area"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#critical-z-value",
    "href": "slides/11-inferential-statistics.html#critical-z-value",
    "title": "Week 11: Inferential Statistics",
    "section": "Critical Z-value",
    "text": "Critical Z-value\n\n\n\nif \\(\\alpha\\) is .05, \\(\\alpha/2\\) is 0.025 and \\(z_{\\alpha/2}\\) is \\(\\pm\\) 1.96\nif \\(\\alpha\\) is .01, \\(\\alpha/2\\) is 0.005, what is \\(z_{\\alpha/2}\\)?\n\n\nFull Unit Normal Table"
  },
  {
    "objectID": "slides/11-inferential-statistics.html#hypothesis-testing",
    "href": "slides/11-inferential-statistics.html#hypothesis-testing",
    "title": "Week 11: Inferential Statistics",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\n\nA null hypothesis \\(H_0\\) can be constructed that says, a sample does not have a sample mean \\(\\bar x\\) that is different from the population mean \\(\\mu\\).\nIf the sample mean turns out to be unusually far from the population mean, the probability, or p value can be reported. Typically, probabilities or p values that are less than 5% are considered significant.\nThe null hypothesis would be rejected and the z-score, p value, mean and standard deviation would be reported."
  },
  {
    "objectID": "slides/11-inferential-statistics.html#activity",
    "href": "slides/11-inferential-statistics.html#activity",
    "title": "Week 11: Inferential Statistics",
    "section": "Activity",
    "text": "Activity\nstats_inferential_activity.ipynb"
  },
  {
    "objectID": "slides/02-data-display.html#goals",
    "href": "slides/02-data-display.html#goals",
    "title": "Week 2: Data Display",
    "section": "Goals",
    "text": "Goals\n\n\nreview display types\nreview anatomy of a graph\ngroup activity"
  },
  {
    "objectID": "slides/02-data-display.html#display-types-1",
    "href": "slides/02-data-display.html#display-types-1",
    "title": "Week 2: Data Display",
    "section": "Display Types",
    "text": "Display Types\n\n\n\n\n\ndata table\npie chart\npoint or dot plot"
  },
  {
    "objectID": "slides/02-data-display.html#pie-chart",
    "href": "slides/02-data-display.html#pie-chart",
    "title": "Week 2: Data Display",
    "section": "Pie Chart",
    "text": "Pie Chart"
  },
  {
    "objectID": "slides/02-data-display.html#dot-plot",
    "href": "slides/02-data-display.html#dot-plot",
    "title": "Week 2: Data Display",
    "section": "Dot Plot",
    "text": "Dot Plot"
  },
  {
    "objectID": "slides/02-data-display.html#additional-types",
    "href": "slides/02-data-display.html#additional-types",
    "title": "Week 2: Data Display",
    "section": "Additional Types",
    "text": "Additional Types\n\n\n\nhistogram\nbar plot\nline plot\nscatter plot\nheat map\nbox and whisker plot\n\n\n\n\n\n← occurrences (binned)\n← processed categories\n← continuous line\n← shows relationships\n← three variables in 2D\n← stat on a variable"
  },
  {
    "objectID": "slides/02-data-display.html#histogram",
    "href": "slides/02-data-display.html#histogram",
    "title": "Week 2: Data Display",
    "section": "Histogram",
    "text": "Histogram"
  },
  {
    "objectID": "slides/02-data-display.html#line-plot",
    "href": "slides/02-data-display.html#line-plot",
    "title": "Week 2: Data Display",
    "section": "Line Plot",
    "text": "Line Plot"
  },
  {
    "objectID": "slides/02-data-display.html#box-and-whisker-plot",
    "href": "slides/02-data-display.html#box-and-whisker-plot",
    "title": "Week 2: Data Display",
    "section": "Box and Whisker Plot",
    "text": "Box and Whisker Plot"
  },
  {
    "objectID": "slides/02-data-display.html#terminology",
    "href": "slides/02-data-display.html#terminology",
    "title": "Week 2: Data Display",
    "section": "Terminology",
    "text": "Terminology\n\n\n\n\n\nlegend\nmarkers\nmarker labels\naxis labels\naxis units\ntick marks\ntitle\ncaption\npanels"
  },
  {
    "objectID": "slides/02-data-display.html#group-activity",
    "href": "slides/02-data-display.html#group-activity",
    "title": "Week 2: Data Display",
    "section": "Group Activity",
    "text": "Group Activity\n\n\nForm pairs\nTake notes\nInterview your partner to find out about a data visualization that they recently admired\nWhat did the visualization make clear that was unclear before?\nWhat were all the salient features used to communicate information?\nPresent your partner’s visualization"
  },
  {
    "objectID": "slides/02-data-display.html#group-activity-2",
    "href": "slides/02-data-display.html#group-activity-2",
    "title": "Week 2: Data Display",
    "section": "Group Activity 2",
    "text": "Group Activity 2\n\n\nForm new pairs\npull up https://www.nytimes.com/2023/07/26/learning/over-75-new-york-times-graphs-for-students-to-analyze.html\nFind a visualization that uses a line plot\nFind a visualization that uses a histogram\nFind a visualization that uses a bar chart\nFind a visualization that uses a heat map\nFind a visualization that uses a scatter plot\nFind a visualization that uses something else\nFind a visualization that is too complicated\nFind a visualization that is collectively your favorite\n\n\nEnd"
  },
  {
    "objectID": "slides/02-data-display.html#end",
    "href": "slides/02-data-display.html#end",
    "title": "Week 2: Data Display",
    "section": "End",
    "text": "End"
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Materials",
    "section": "",
    "text": "Welcome\n\nWeek One: January 14, 16: Setup\n\nReading: Making Sense of Data II, Chapter 2, p. 19-32\nSlides: Welcome Reveal, Welcome PDF\nLab: Practice Lab Due: Thursday Jan 23, 2:30pm\n\n\nData Display\n\nWeek Two: January 21, 23: Display Types and Anatomy of a Chart\n\nReading: Making Sense of Data II, Chapter 2, p. 32-50\nSlides: Display Types and Anatomy of a Chart Reveal, PDF\nClass Activity: Data Display\nLab: Data Display Due: Thursday Jan 30, 2:30pm\n\nWeek Three: January 28, 30: Data Distortion\n\nReading: Misleading Graphs\nClass Activity: Data Distortion\nLab: Data Distortion Due: Thursday Feb 6, 2:30pm\n\nWeek Four: February 4, 7: Data Filtering\n\nVideo: Logical Indexing\nClass Activity: Data Filtering\nLab: Data Filtering Due: Thursday Feb 13, 2:30pm\nActivities Repo\n\nWeek Five: February 11, 13: Interactive Display\n\nExplore: Interactive Viz Gallery\nClass Activity: Data Interactivity\nLab: Data Interactivity Due: Thursday Feb 20, 2:30pm\n\n\nData Gathering\n\nWeek Six: February 18, 20: Turning Anything Into Data\n\nReading: Variable Types\nSlides: Data Gathering\nClass Activity: Google Form Data\nClass Activity: Make data-gathering-activity.csv\nLab: Data Entry Due: Thursday Feb 27, 2:30pm\n\nWeek Seven: February 25, 27: Web Data Analytics and Scraping\n\nReading: Site Maps\nSlides: Gathering Web Data\nClass Activity Optional: Make data-scraping-activity.csv\nLab: Data Analytics Due Thursday March 13, 2:30pm \n\nSpring Break: March 1-9\nWeek Nine: March 11, 13: Data Wrangling\n\nReading: Making Sense of Data I, Chapter 3, Preparing Data Tables \nClass Activity: Data Wrangling Notebook\nLab: Data Wrangling Due Thursday, March 27, 2:30pm\n\n\nData Processing\n\nWeek Ten: March 18, 20: Statistics Intro\n\nReading: Making Sense of Data I, Chapter 2, Describing Data, p. 17-37\nSlides: Data Descriptors\nClass Activity: Stats Intro Notebook\nLab: No new lab\n\nWeek Eleven: March 25, 27: Inferential Statistics\n\nReading: Making Sense of Data I, Chapter 2, Describing Data, p. 37-42\nSlides: Inferential Statistics\nClass Activity: Inferential Stats Activity\nLab: Final Project Proposal Due Thursday, April 3, 2:30pm\n\nWeek Twelve: April 1, 3: Comparing and Modeling\n\nReading: Making Sense of Data I, Chapter 4, Understanding Relationships\nSlides: Hypothesis Testing and Correlation\nClass Activity: Data Analysis Activity\nReading: Making Sense of Data I, Chapter 6, Linear Regression, p. 149-158\nSlides: Linear Regression\nExamples in Code: Linear Regression\nLab: Song Data Analysis Due Thursday, April 17th, 2:30pm\n\nWeek Thirteen: April 8: Clustering\n\nReading: Making Sense of Data I, Chapter 5, Groups in Data\nVideo: K-Means Clustering 4:15-19:45 Ad-Free Version\nClass Activity: K-Means Clustering Activity\n\n\nData Storytelling\n\nWeek Fourteen: April 15, 17: Storytelling\n\nReading: Scientific Writing\nSlides: Creating a Research Narrative\nClass Activity:\nLab: \n\nWeek Fifteen: April 22, 24: Project Preparation\n\nFinal Presentations Code C\n\nThursday, May 1st, 2025 at 7:00 PM: Final Project Lightning Talks"
  }
]